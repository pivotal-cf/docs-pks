---
title: Deploying and Managing Cloud Native Storage (CNS) on vSphere
owner: TKGI
---

This topic describes how to use the vSphere Container Storage Interface (CSI) Driver 
that is automatically installed to clusters by <%= vars.product_full %> (<%= vars.k8s_runtime_abbr %>) on vSphere.  

If your <%= vars.k8s_runtime_abbr %> environment is on vSphere and your administrator has not enabled automatic vSphere CSI Driver installation, 
you must manually install a vSphere CSI Driver on your clusters. For more information, 
see [Manually Installing the vSphere CSI Driver](vsphere-cns-manual.html).  

## <a id='overview'></a>Overview

vSphere Cloud Native Storage (CNS) provides comprehensive data management for stateful, containerized apps,
enabling apps to survive restarts and outages.
Stateful containers can use vSphere storage primitives such as standard volume, persistent volume, and dynamic provisioning, 
independent of VM and container lifecycle.  

You can install vSphere CNS on <%= vars.k8s_runtime_abbr %>-provisioned clusters by configuring <%= vars.k8s_runtime_abbr %> 
to automatically install a vSphere CSI Driver. 
To enable automatic CSI driver installation on your clusters, 
see [Storage](installing-vsphere.html#storage-config) in _Installing <%= vars.k8s_runtime_abbr %> on vSphere_.  

When automatic vSphere CSI Driver installation is enabled, your clusters 
use your tile **Kubernetes Cloud Provider** storage settings as the default vSphere CNS configuration.  

The automatically deployed vSphere CSI Driver supports high availability (HA) configurations. HA support 
is automatically enabled on clusters with multiple control plane nodes and uses only one active CSI Controller.  

Use the vSphere client to review your cluster storage volumes and their backing virtual disks, and to 
set a storage policy on your storage volumes or monitor policy compliance. 
vSphere storage backs up your cluster volumes.  

For more information about VMware CNS, see [Getting Started with VMware Cloud Native Storage](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.storage.doc/GUID-CF1D7196-E49C-4430-8C50-F8E35CAAE060.html).  

For more information about using the Kubernetes CSI Driver, see
[Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) in the Kubernetes documentation.  


In <%= vars.k8s_runtime_abbr %>, you can use the vSphere CSI Driver to:  

* Customize, deploy and manage vSphere CNS volumes:  
    * To customize file volumes, see [Customize vSphere File Volumes](#create-file-volumes) below.  
    * To use and customize CNS Volumes, see [Create or Use CNS Block Volumes](#use-cns) below.  
* Apply vSphere Topology-Aware Volume Provisioning to your cluster.
<br>    
    For more information, see [Customize a Cluster with vSphere Topology-Aware Volume Provisioning](#vsphere-topology-provisioning) below.  

<br>
<p class="note"><strong>Note</strong>: If you have an existing cluster with a manually installed vSphere CSI driver 
and your administrator has enabled automatic vSphere CSI Driver installation, you must uninstall the manually installed vSphere CSI Driver 
from your cluster. 
For more information, see <a href="#uninstall-csi">Uninstall a Manually Installed vSphere CSI Driver</a> below.
</p>




### <a id='supported-feature'></a> vSphere CSI Driver Supported Features and Requirements

The vSphere CSI Driver supports different features depending on driver version, environment and storage type.  

<%= vars.k8s_runtime_abbr %> supports only the following vSphere CSI Driver features:  

* Dynamic Block PV support<sup>&#42;</sup>  
* Dynamic File PV support<sup>&#42;</sup>  
* Dynamic Virtual Volume (vVOL) PV support  
* Encryption support via VMcrypt<sup>&#42;</sup>  
* Enhanced Object Health in UI for vSAN Datastores  
* Kubernetes Multi-node Control Plane support  
* Static PV Provisioning  
* Topology-aware volume provisioning  
<br>

    <sup>&#42;</sup>For information on the usage limitations and environment and version requirements of these vSphere CSI Driver features, 
    see [Functionality Supported by vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-E59B13F5-6F49-4619-9877-DF710C365A1E.html#functionality-supported-by-vsphere-container-storage-plugin-0) 
    in _Supported Kubernetes Functionality and Limitations_ in the VMware vSphere Container Storage Plug-in documentation.  

<br>
For information on the vCenter, datastore, and cluster types supported by the vSphere CSI Driver, see 
[vSphere Functionality Supported by vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-5B7955AA-E720-4C73-8330-1C34A0B054B3.html) 
 in the VMware vSphere Container Storage Plug-in documentation.  

For information on the scaling limitations of the vSphere CSI Driver, see 
[Configuration Maximums for vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-C0350554-F5DB-4C27-9786-720AC0F0B28A.html) 
 in the VMware vSphere Container Storage Plug-in documentation.  



## <a id='create-file-volumes'></a>Customize vSphere File Volumes

To create, modify or remove a customized vSphere file volume:  

* [Create a Cluster with Customized File Volume Parameters](#file-volumes-create)  
* [Modify a Cluster with Customized File Volume Parameters](#file-volumes-modify)  
* [Remove File Volume Parameters from a Cluster](#file-volumes-remove)  

### <a id='file-volumes-prereqs'></a>Prerequisites 

To use file volumes, you must enable vSAN File Services in the vSphere vCenter. 
For information about enabling vSAN File Services, see 
[Configure File Services](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vsan.doc/GUID-CA9CF043-9434-454E-86E7-DCA9AD9B0C09.html) 
in the VMware vSphere documentation.  

To use the vSphere CSI Driver's topology-aware volume provisioning features, you must prepare your vSphere environment. For more information, see
[Prepare for Topology](#prepare-for-topology) below.   


### <a id='file-volumes-create'></a>Create a Cluster with Customized File Volume Parameters

To create a new cluster with a vSphere file volume:  

1. Create a JSON or YAML formatted volume configuration file containing the following:  

    ```
    {
      "target_vsan_fileshare_datastore_urls": "DS-URLS",
      "net_permissions": [
        {
          "name": "PERMISSION-NAME",
          "ips": "IP-ADDRESS",
          "permissions": "PERMISSION",
          "rootsquash": ROOT-SQUASH
        },
        {
          "name": "PERMISSION-NAME",
          "ips": "IP-ADDRESS",
          "permissions": "PERMISSION",
          "rootsquash": ACCESS-LEVEL
        },
      ]
    }
    ```
    
    Where:  
    
    * `DS-URLS` is a comma-separated list of datastores for deploying file share volumes. 
    For example: `"ds:///vmfs/volumes/vsan:52635b9067079319-95a7473222c4c9cd/"`.  
    * `PERMISSION-NAME` is your name for a NetPermission.  
    * `IP-ADDRESS` is the IP range or IP subnet affected by a NetPermission restriction.  
    * `PERMISSION` is the access permission to the file share volume for a NetPermission restriction.  
    * `ACCESS-LEVEL` is the security access level for the file share volume for a NetPermission restriction.  

    For information, see [File Volume Configuration](#file-volumes-params) below.  
    
1. To create a cluster with attached file volumes:

    ```
    tkgi create-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```
    
    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  

    For example:
    <pre class="terminal">
    $ tkgi create-cluster demo -e demo.cluster --plan Small --config-file ./conf1.json
    </pre>


### <a id='file-volumes-modify'></a>Modify a Cluster with Customized File Volume Parameters

To modify an existing cluster with a vSphere file volume:  

1. Create a file volume configuration file. For information, see [File Volume Configuration](#file-volumes-params) below.   
1. To update your cluster with file volumes:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  
    
    
### <a id='file-volumes-remove'></a>Remove File Volume Parameters from a Cluster

To remove a vSphere file volume configuration from a cluster:  

1. Create a file volume configuration file containing either the `disable_target_vsan_fileshare_datastore_urls` or `disable_net_permissions`
parameters set to `true` to disable an existing file volume parameter.  
<br>
    For more information, see [File Volume Configuration](#file-volumes-params) below.  
    
1. To remove the configured file volume parameter from your cluster:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  

<%# Examples: https://confluence.eng.vmware.com/pages/viewpage.action?spaceKey=PKS&title=Detailed+design+document+for+supporting+file+volume+specific+configurations #%>

### <a id='file-volumes-params'></a>File Volume Configuration

Create a JSON or YAML formatted File Volume configuration file to enable or disable vSphere file volume support.  

For example:  

* The following configuration enables all File Volume features:  

    ```
    {
      "target_vsan_fileshare_datastore_urls": "ds:///vmfs/volumes/vsan:52635b9067079319-95a7473222c4c9cd/",
      "net_permissions": [
        {
          "name": "demo1",
          "ips": "192.168.0.0/16",
          "permissions": "READ_WRITE",
          "rootsquash": false
        },
        {
          "name": "demo2",
          "ips": "10.0.0.0/8",
          "permissions": "READ_ONLY",
          "rootsquash": false
        }
      ]
    }
    ```
    
* The following configuration disables File Volume features:  

    ```
    {
      "disable_target_vsan_fileshare_datastore_urls": true,
      "disable_net_permissions": true
    }
    ```
    
    
#### <a id='file-volumes-params-datastores'></a>File Volume DataStores Configuration

The following are accepted Datastore URLs parameters:  

<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>target_vsan_fileshare_datastore_urls</td>
        <td>string</td>
        <td>A comma separated list of datastores for deploying file share volumes.</td>
    </tr>
    <tr>
        <td>disable_target_vsan_fileshare_datastore_urls</td>
        <td>Boolean</td>
        <td>Disable the target_vsan_fileshare_datastore_urls.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
</table>


#### <a id='file-volumes-params-netperm'></a>File Volume NetPermissions Object Configuration

The following are accepted NetPermissions objects:  
<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>net_permissions</td>
        <td>Array</td>
        <td>Properties defining a NetPermissions object.</td>
    </tr>
    <tr>
        <td>disable_net_permissions</td>
        <td>Boolean</td>
        <td>Disable the net_permissions.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
</table>  

The following are supported NetPermissions object parameters:  
<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>name</td>
        <td>string</td>
        <td>Name of the NetPermission object.</td>
    </tr>
    <tr>
        <td>ips</td>
        <td>string</td>
        <td>IP range or IP subnet affected by the NetPermission restrictions.<br>Default Value: <code>"*"</code>.</td>
    </tr>
    <tr>
        <td>permissions</td>
        <td>string</td>
        <td>Access permission to the file share volume.<br>Values: <code>"READ_WRITE"</code>, <code>"READ_ONLY"</code>, <code>"NO_ACCESS"</code>.<br>Default Value: <code>"READ_WRITE"</code>.</td>
    </tr>
    <tr>
        <td>rootsquash</td>
        <td>Boolean</td>
        <td>Security access level for the file share volume.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
</table>


<%#FROM Confluence:  PKS Core pks-api/spec.yaml: https://confluence.eng.vmware.com/pages/viewpage.action?spaceKey=PKS&title=Detailed+design+document+for+supporting+file+volume+specific+configurations #%>

## <a id='use-cns'></a> Create or Use CNS Block Volumes

To dynamically provision a block volume using the vSphere CSI Driver:  

1. [Create a vSphere Storage Class](#create-storage)
1. [Create a PersistentVolumeClaim](#persistent-volumes-create)
1. [Create Workloads Using Persistent Volumes](#persistent-volumes-workloads)

For more information on vSphere CSI Driver configuration, see the `example/vanilla-k8s-block-driver` configuration 
for the CSI driver version you are using 
in [vsphere-csi-driver](https://github.com/kubernetes-sigs/vsphere-csi-driver/) in the VMware kubernetes-sigs GitHub repo.  


### <a id='create-storage'></a>Create a vSphere Storage Class

To create a vSphere Storage Class:

1. Open vCenter.
1. Open the vSAN Datastore Summary pane.

    ![vSAN Datastore Summary pane in vCenter](images/vsphere/datastore.png)

1. Determine the `datastoreurl` value for your Datastore.  
1. Create the following YAML:

    ```
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: demo-sts-storageclass
      annotations:
          storageclass.kubernetes.io/is-default-class: "true"
    provisioner: csi.vsphere.vmware.com
    allowVolumeExpansion: ALLOW-EXPANSION
    parameters:
      datastoreurl: "DATASTORE-URL"
    ```

    Where:  

    * `ALLOW-EXPANSION` defines whether the cluster's persistent volume size is either resizable or static. 
    Set to `true` for resizable and `false` for static size.  
    * `DATASTORE-URL` is the URL to your Datastore. 
    For a non-vSAN datastore, the `datastoreurl` value looks like 
    `ds:///vmfs/volumes/5e66e525-8e46bd39-c184-005056ae28de/`.  
<br>
    For example:

    ```
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: demo-sts-storageclass
      annotations:
          storageclass.kubernetes.io/is-default-class: "true"
    provisioner: csi.vsphere.vmware.com
    allowVolumeExpansion: true
    parameters:
      datastoreurl: "ds:///vmfs/volumes/vsan:52d8eb4842dbf493-41523be9cd4ff7b7/"
    ```
For more information about StorageClass, see [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) in the Kubernetes documentation.




### <a id='persistent-volumes-create'></a>Create a PersistentVolumeClaim

To create a Persistent Volume using the vSphere CSI Driver:

1. Create a Storage Class. For more information, see [Create a vSphere Storage Class](#create-storage) below.  
1. To apply the StorageClass configuration:
    ```
    kubectl apply -f CONFIG-FILE
    ```
    Where `CONFIG-FILE` is the name of your StorageClass configuration file. 
1. Create the PersistentVolumeClaim configuration for the file volume.
For information about configuring a PVC, see [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) in the Kubernetes documentation.      
<br>
     <%# (Note only for Ollie: When the PVC is created then the corresponding PV will be created automatically, but could be delayed based on StorageClass config)
     FROM github:  https://github.com/kubernetes-sigs/vsphere-csi-driver/tree/master/example/vanilla-k8s-block-driver
     Use example of example-pvc.yaml: https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/master/example/vanilla-k8s-block-driver/example-pvc.yaml #%>
    For example:  

    ```
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: example-vanilla-block-pvc
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 5Gi
      storageClassName: example-vanilla-block-sc
    ```
1. To apply the PVC configuration:  

    ```
    kubectl apply -f CONFIG-FILE 
    ```

    Where `CONFIG-FILE` is the name of your PVC configuration file.  


### <a id='persistent-volumes-workloads'></a>Create Workloads Using Persistent Volumes

1. Create a Pod configuration file containing `volumeMounts` and `volumes` parameters.  
<br>
    For example:  

    ```
    apiVersion: v1
    kind: Pod
    metadata:
      name: example-vanilla-block-pod
    spec:
      containers:
        - name: test-container
          image: gcr.io/google_containers/busybox:1.24
          command: ["/bin/sh", "-c", "echo 'hello' > /mnt/volume1/index.html  && chmod o+rX /mnt /mnt/volume1/index.html && while true ; do sleep 2 ; done"]
          volumeMounts:
            - name: test-volume
              mountPath: /mnt/volume1
      restartPolicy: Never
      volumes:
        - name: test-volume
          persistentVolumeClaim:
            claimName: example-vanilla-block-pvc
    ```
    <%# example-pod.yaml  https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/master/example/vanilla-k8s-block-driver/example-pod.yaml #%>

1. To apply the Pod configuration to your workload:  

    ```
    kubectl apply -f CONFIG-FILE 
    ```

    Where `CONFIG-FILE` is the name of your configuration file.  

For more information and examples of Pod configurations, see the `example` configurations 
for the CSI driver version you are using 
in [vsphere-csi-driver](https://github.com/kubernetes-sigs/vsphere-csi-driver/) in the VMware kubernetes-sigs GitHub repo.





## <a id='vsphere-topology-provisioning'></a>Customize a Cluster with vSphere Topology-Aware Volume Provisioning

<%= vars.k8s_runtime_abbr %> supports the vSphere Container Storage Plug-in's topology-aware volume provisioning features.  

To create, modify or remove Topology-Aware Volume Provisioning on a cluster:  

* [Prepare for Topology](#prepare-for-topology)  
* [Create a Cluster with Topology](#create-topology)  
* [Modify a Cluster with Topology](#modify-topology)  
* [Remove Topology from a Cluster](#remove-topology)  


For more information on volume provisioning features, see [Allowed Topologies](https://kubernetes.io/docs/concepts/storage/storage-classes/#allowed-topologies) in the Kubernetes documentation 
and [Topology-Aware Volume Provisioning](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-61646244-E24F-4E7E-AB1A-F95B5A5DD518.html) 
in the VMware vSphere Container Storage Plug-in documentation.  


### <a id='prereqs-topology'></a>Topology Prerequisites 

<%= vars.k8s_runtime_abbr %> support for Topology-aware volume provisioning requires:

* The **vSphere CSI Driver Integration** option must be enabled on the <%= vars.k8s_runtime_abbr %> tile. 
For more information, see [Storage](installing-vsphere.html#storage-config) in installing <%= vars.k8s_runtime_abbr %> on vSphere.  

* You have created vSphere CSI topology labels and categories in your vSphere environment. 
For more information, see [Prepare for Topology](#prepare-for-topology) below.   


### <a id='prepare-for-topology'></a>Prepare for Topology

Before creating a new cluster or updating an existing cluster with Topology-aware volume provisioning:  

1. Verify your environment meets the [Topology Prerequisites](#prereqs-topology) above.  
1. Create the following vSphere Center categories:  
    1. A region category with **Multiple Cardinality** disabled. For example, `k8s-region`.  
    1. A zone category with **Multiple Cardinality** disabled. For example, `k8s-zone`.  
1. Create the following vSphere Center tags:  
    1. A region tag for your clusters in the region category you created above. For example, a `region-1` tag in the `k8s-region` category.   
    1. Availability zone tags for your clusters in the zone category you created above. For example, `az-0` to `az-5` tags in the `k8s-zone` category.  
    
For more information on creating vSphere Center tags and categories, 
see [Create, Edit, or Delete a Tag Category](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vcenterhost.doc/GUID-BA3D1794-28F2-43F3-BCE9-3964CB207FB6.html) 
in the VMware vSphere documentation.  


### <a id='create-topology'></a>Create a Cluster with Topology

To create a new cluster with a vSphere Topology configuration:  

1. Create a JSON or YAML configuration file containing the following:  

    ```
    {
      "csi_topology_labels": {
        "topology_categories": "REGION-TAG,ZONE-TAG"
      }
    }
    ```
    
    Where:  
    
    * `REGION-TAG` is the vSphere Center region tag you created in [Prepare for Topology](#prepare-for-topology) above.  
    * `ZONE-TAG` is one of the vSphere Center zone tags you created in [Prepare for Topology](#prepare-for-topology) above.  

    For example:  

    ```
    {
      "csi_topology_labels": {
        "topology_categories": "k8s-region,k8s-zone"
      }
    }
    ```
    
    For more information, see [Topology Configuration](#params-topology) below.  
    
1. To create a cluster with Topology-aware volume provisioning:

    ```
    tkgi create-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```
    
    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  

    For example:
    <pre class="terminal">
    $ tkgi create-cluster demo -e demo.cluster --plan Small --config-file ./conf1.json
    </pre>


### <a id='modify-topology'></a>Modify a Cluster with Topology

To modify an existing cluster to have a vSphere Topology configuration:  

1. Create a configuration file containing the following:  

    ```
    {
      "csi_topology_labels": {
        "topology_categories": "REGION-TAG,ZONE-TAG"
      }
    }
    ```
    
    Where:  
    
    * `REGION-TAG` is the vSphere Center region tag you created in [Prepare for Topology](#prepare-for-topology) above.  
    * `ZONE-TAG` is one of the vSphere Center zone tags you created in [Prepare for Topology](#prepare-for-topology) above.  
<br>
    For more information, see [Topology Configuration](#params-topology) below.  
    
    <p class="note"><strong>Note</strong>: If you have an existing cluster created using a manually installed vSphere CSI Driver 
        and topology is enabled on the cluster, your existing configuration uses separate <code>"region"</code> and <code>"zone"</code>
        parameters instead of a single <code>"topology_categories"</code> parameter. 
        You must use the legacy <code>"region"</code> and <code>"zone"</code> parameters in your configuration 
        when updating a migrated cluster with existing legacy topology support.
    </p>
    
1. To update your cluster with Topology-aware volume provisioning:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  
 
    
### <a id='remove-topology'></a>Remove Topology from a Cluster

To remove a Topology configuration from a cluster:  

1. Create a configuration file containing the following:  

    ```
    {
      "csi_topology_labels": {
        "topology_categories": ""
      }
    }
    ```
<br>
    For more information, see [Topology Configuration](#params-topology) below.  
    
    <p class="note"><strong>Note</strong>: If you have an existing cluster created using a manually installed vSphere CSI Driver 
        and topology is enabled on the cluster, your existing configuration uses separate <code>"region"</code> and <code>"zone"</code>
        parameters instead of a single <code>"topology_categories"</code> parameter. 
        You must use the legacy <code>"region"</code> and <code>"zone"</code> parameters in your configuration 
        when updating a migrated cluster with existing legacy topology support.
    </p>
    
1. To remove the configured Topology-aware volume provisioning from your cluster:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  


#### <a id='params-topology'></a>Topology Configuration

The following are accepted CSI Topology Labels objects:  
<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>csi_topology_labels</td>
        <td>object</td>
        <td>Properties defining a CSI Topology Labels object.</td>
    </tr>
</table>  

The following are supported CSI Topology Labels object parameters:  
<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>topology_categories</td>
        <td>string</td>
        <td>A comma delimited list of vSphere Center tags to apply to the File Volume.</td>
    </tr>
</table>


## <a id='uninstall-csi'></a>Uninstall a Manually Installed vSphere CSI Driver

If your administrator has enabled automatic vSphere CSI Driver Integration and you have a cluster that uses a manually installed vSphere CSI Driver, 
the manually installed driver will no longer function after upgrading the cluster.   

To uninstall a manually installed CSI driver:

1. Confirm your <%= vars.k8s_runtime_abbr %> administrator has enabled automatic **vSphere CSI Driver Integration** on the <%= vars.k8s_runtime_abbr %> tile.
2. Upgrade your Kubernetes cluster to the <%= vars.k8s_runtime_abbr %> version of the <%= vars.k8s_runtime_abbr %> tile.
3. Remove the manually installed CSI driver from the cluster. 
For more information, see [Remove a Manually Installed vSphere CSI Driver](#manually-remove-csi) below.  
<%# 
4. Validate that CNS recognizes the existing storage.  
by completing the steps in
[Create and Manage vSphere CNS Volumes](#overview-managing) above.  
#%>
4. To restart CSI jobs, restart `csi-node-registrar` and `csi-node` on each worker node:  
    * To restart `csi-node-registrar`:  
    
        ```
        bosh -d DEPLOYMENT ssh WORKER-NODE
        sudo bash
        monit restart csi-node-registrar
        ```
        
        Where:  
        
        * `DEPLOYMENT` is the name of the deployment.  
        * `WORKER-NODE` is the worker node VM.  
    * To restart `csi-node`:  
    
        ```
        bosh -d DEPLOYMENT ssh WORKER-NODE
        sudo bash
        monit restart csi-node
        ```
        
        Where:  
        
        * `DEPLOYMENT` is the name of the deployment.  
        * `WORKER-NODE` is the worker node VM.  

5. To verify the CSI jobs are in running state, run the following on each control plane node: 

    ```
    bosh -d DEPLOYMENT ssh CONTROL-PLANE-NODE
    sudo bash
    monit summary | grep csi
    ```

    Where:  

    * `DEPLOYMENT` is the name of the deployment.  
    * `CONTROL-PLANE-NODE` is the control plane node VM.  

6. To restart a CSI job that is not in running state:  

    ```
    monit restart JOB-NAME
    ```

    Where `JOB-NAME` is the name of the CSI job to restart.  




### <a id='manually-remove-csi'></a>Remove a Manually Installed vSphere CSI Driver

If you have a cluster that uses a manually installed vSphere CSI Driver, 
and you upgrade the cluster after your administrator has enabled automatic vSphere CSI Driver Integration,
you should remove the manually installed driver. 
While automatic vSphere CSI Driver Integration is enabled, 
<%= vars.k8s_runtime_abbr %> enables the integrated driver for a cluster after upgrading it, 
and the cluster's manually installed driver no longer functions.  

To remove a manually installed vSphere CSI driver:

1. Create a manifest `remove-vsphere-csi-node-ds.yaml` that removes the CSI controller `DaemonSet`.

1. Remove the DaemonSet:

    ```
    kubectl apply -f remove-vsphere-csi-node-ds.yaml
    ```

1. Create a manifest `remove-vsphere-csi-controller-deployment.yaml` that removes the deployment and `CSIDriver` objects for the CSI controller.

1. Remove the CSI driver objects:

    ```
    kubectl apply -f remove-vsphere-csi-controller-deployment.yaml
    ```

1. Create a manifest `remove-vsphere-csi-controller-rbac.yaml` that removes the RBAC rules.

1. Remove the RBAC resource:

    ```
    kubectl apply -f remove-vsphere-csi-controller-rbac.yaml
    ```

<%#
If users manually deployed the vSphere CSI Driver previously, and they want to enable vSphere CSI Driver in TKGI 1.11 tile, 
then they must manually delete the manually deployed CSI Drive after successfully upgrading the K8S cluster to TKGI 1.11. 
Please note that the key point is the timing, in other words, 
they can't delete the manually deployed vSphere CSI Driver before upgrading the existing cluster(s); 
Instead, they should perform the operation after upgrading the existing cluster(s). 
We need to get the above info included in the document. #%>

## <a id='migrate-to-csi'></a> Migrate an In-Tree vSphere Storage Volume to the vSphere CSI Driver

Kubernetes' support for in-tree vSphere storage volumes has been deprecated, and support will be removed in a future Kubernetes version.  

The <%= vars.k8s_runtime_abbr %> v1.15 upgrade process will automatically migrate your in-tree vSphere storage volumes to vSphere CSI. 
If you have existing clusters that use in-tree vSphere storage volumes, you can continue to use the volumes with your current version of TKGI, but 
VMware strongly recommends that you migrate your in-tree vSphere storage volumes to vSphere CSI volumes before upgrading to <%= vars.k8s_runtime_abbr %> v1.15.  

To manually migrate a cluster from an in-tree vSphere storage volume to a vSphere CSI Driver volume, see [Migrate In-Tree vSphere Storage Volumes to the vSphere CSI Driver](#migrate-volumes) below.  

To prepare <%= vars.k8s_runtime_abbr %> to use vSphere CSI Driver volumes by default 
and to automatically migrate clusters from in-tree vSphere storage volumes to vSphere CSI Driver volumes during the TKGI v1.15 upgrade, 
see [Prepare for Automatic Migration of Volumes from VCP to CSI](#prepare-to-migrate) below.  



### <a id='prepare-to-migrate'></a> Prepare for Automatic Migration of Volumes from In-Tree vSphere Storage to CSI

If your existing clusters have in-tree vSphere storage volumes, you must prepare for them to be automatically migrated before upgrading to <%= vars.k8s_runtime_abbr %> 1.15.  

To prepare for automatic migration from in-tree vSphere storage volumes to vSphere CSI:  

1. Enable **vSphere CSI Drive Integration** on the <%= vars.product_tile %> tile.  For more information, 
see [Storage](installing-vsphere.html#storage) in _Installing <%= vars.k8s_runtime_abbr %> on vSphere_.  
1. (Optional) Test migrating your in-tree vSphere storage volumes to vSphere CSI volumes prior to upgrading to <%= vars.k8s_runtime_abbr %> 1.15. 
See [Migrate In-Tree vSphere Storage Volumes to the vSphere CSI Driver](#migrate-volumes) below.  
1. (Optional) To avoid a slow upgrade to <%= vars.k8s_runtime_abbr %> v1.15, migrate your in-tree vSphere storage volumes to the vSphere CSI Driver before upgrading. 
See [Migrate In-Tree vSphere Storage Volumes to the vSphere CSI Driver](#migrate-volumes) below.  

<p class="note"><strong>Note</strong>: VMware strongly recommends that you migrate your in-tree vSphere storage volumes to vSphere CSI volumes as soon as possible.
</p>


### <a id='migrate-volumes'></a> Migrate In-Tree vSphere Storage Volumes to the vSphere CSI Driver

You can use `tkgi update-cluster` to migrate the PersistentVolume (PV) and PersistentVolumeClaim (PVC) on an existing <%= vars.k8s_runtime_abbr %> cluster 
from the In-Tree vSphere Storage Driver to the automatically installed vSphere CSI Driver.

<p class="note warning"><strong>Warning</strong>: Due to Known Issues in the vSphere CSI Driver, 
    <%= vars.recommended_by %> recommends that you migrate to the vSphere CSI Driver after upgrading to <%= vars.k8s_runtime_abbr %> v1.13.0 or later.
</p>

Migrating a <%= vars.k8s_runtime_abbr %> cluster from the In-Tree vSphere Storage Driver to the vSphere CSI Driver requires the following:  

* You must use <%= vars.k8s_runtime_abbr %> CLI v1.12 or later.  
* <%= vars.k8s_runtime_abbr %> automatic vSphere CSI Driver integration must be enabled. 
    For information on enabling the **vSphere CSI Driver Integration** option on the <%= vars.k8s_runtime_abbr %> tile, see [Storage](installing-vsphere.html#storage-config) in 
    _Installing <%= vars.product_short %> on vSphere_.  
* <%= vars.k8s_runtime_abbr %> must be installed on vSphere v7.0 U1 or later.  
* The cluster must be a Linux <%= vars.k8s_runtime_abbr %> cluster.  

<br>
To migrate a cluster from an In-Tree vSphere Storage Driver to the vSphere CSI Driver:

<%#1. Confirm your < %= vars.k8s_runtime_abbr % > administrator has enabled automatic **vSphere CSI Driver Integration** on the < %= vars.k8s_runtime_abbr % > tile. %>
1. Upgrade your Kubernetes cluster to the current <%= vars.k8s_runtime_abbr %> version of the <%= vars.k8s_runtime_abbr %> tile.  
1. Review and complete all relevant steps documented in the vSphere CSI Migration documentation:  
    * [Prerequisites for Installing the vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-0AB6E692-AA47-4B6A-8CEA-38B754E16567.html)  
    * [Migrating In-Tree vSphere Volumes to vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-968D421F-D464-4E22-8127-6CB9FF54423F.html#considerations-for-migration-of-intree-vsphere-volumes-0)  
    * [vSphere Container Storage Plug-in Upgrade Considerations and Guidelines](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-3F277B52-68CC-4125-AD0F-E7293940B4B4.html#vsphere-container-storage-plugin-upgrade-considerations-and-guidelines-0)  

    <p class="note warning"><strong>Warning</strong>: Before migrating to the vSphere CSI driver, 
    confirm your cluster's volume storage is configured as described in 
    <a href="https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-968D421F-D464-4E22-8127-6CB9FF54423F.html#considerations-for-migration-of-intree-vsphere-volumes-0">
    Considerations for Migration of In-Tree vSphere Volumes</a>.
    </p>
    
1. Create a configuration file containing the following:  

    ```
    {
        "enable_csi_migration": "true"
    }
    ```
1. To migrate your cluster to the vSphere CSI Driver:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of the config file you created in the preceding steps.  
    
<p class="note"><strong>Note</strong>: You cannot migrate the PV or the PVC 
    on a cluster from the vSphere CSI Driver to the In-Tree vSphere Storage Driver.
</p>
