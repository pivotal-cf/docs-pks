---
title: Deploying and Managing Cloud Native Storage (CNS) on vSphere
owner: TKGI
---

This topic describes how to use the vSphere Container Storage Interface (CSI) Driver 
that is automatically installed to clusters by <%= vars.product_full %> (<%= vars.k8s_runtime_abbr %>) on vSphere.  

<br>
## <a id='overview'></a>Overview

vSphere Cloud Native Storage (CNS) provides comprehensive data management for stateful, containerized apps,
enabling apps to survive restarts and outages.
Stateful containers can use vSphere storage primitives such as standard volume, persistent volume, and dynamic provisioning, 
independent of VM and container lifecycle.  

You can install vSphere CNS on <%= vars.k8s_runtime_abbr %>-provisioned clusters by configuring <%= vars.k8s_runtime_abbr %> 
to automatically install a vSphere CSI Driver. 
To enable automatic CSI driver installation on your clusters, 
see [Storage](installing-vsphere.html#storage-config) in _Installing <%= vars.k8s_runtime_abbr %> on vSphere_.  

When automatic vSphere CSI Driver installation is enabled, your clusters 
use your tile **Kubernetes Cloud Provider** storage settings as the default vSphere CNS configuration.  

The automatically deployed vSphere CSI Driver supports high availability (HA) configurations. HA support 
is automatically enabled on clusters with multiple control plane nodes and uses only one active CSI Controller.  

Use the vSphere client to review your cluster storage volumes and their backing virtual disks, and to 
set a storage policy on your storage volumes or monitor policy compliance. 
vSphere storage backs up your cluster volumes.  

For more information about VMware CNS, see [Getting Started with VMware Cloud Native Storage](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.storage.doc/GUID-CF1D7196-E49C-4430-8C50-F8E35CAAE060.html).  

For more information about using the Kubernetes CSI Driver, see
[Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) in the Kubernetes documentation.  


In <%= vars.k8s_runtime_abbr %>, you can configure the vSphere CSI Driver to:  


    
* Customize, deploy and manage vSphere CNS volumes:  
    * To customize file volumes, see [Customize vSphere File Volumes](#create-file-volumes) below.  
    * To use and customize CNS Volumes, see [Create or Use CNS Block Volumes](#use-cns) below.  

* Apply vSphere Topology-Aware Volume Provisioning to your cluster.  
<br>    
    For more information, see 
    [Customize a Cluster with vSphere Topology-Aware Volume Provisioning](#vsphere-topology-provisioning) below.  
* Customize and manage vSphere CNS:  
    * To use CNS in a multi-data center environment, see [Configure CNS Data Centers](#cns-datacenters) below.  
    * [Switch From the Manually Installed vSphere CSI Driver to the Automatic CSI Driver](#uninstall-csi)
    

<br>
<p class="note"><strong>Note</strong>: If you have an existing cluster with a manually installed vSphere CSI driver 
and your administrator has enabled automatic vSphere CSI Driver installation, you must uninstall the manually installed vSphere CSI Driver 
from your cluster. 
For more information, see <a href="#uninstall-csi">Uninstall a Manually Installed vSphere CSI Driver</a> below.
</p>
<br>


<br>
### <a id='supported-feature'></a> vSphere CSI Driver Supported Features and Requirements

The vSphere CSI Driver supports different features depending on driver version, environment and storage type.  

<%= vars.k8s_runtime_abbr %> supports only the following vSphere CSI Driver features:  

* Dynamic Block PV support<sup>&#42;</sup>  
* Dynamic File PV support<sup>&#42;</sup>  
* Dynamic Virtual Volume (vVOL) PV support  
* Encryption support via VMcrypt<sup>&#42;</sup>  
* Enhanced Object Health in UI for vSAN Datastores  
* Kubernetes Multi-node Control Plane support  
* Static PV Provisioning  
* Topology-aware volume provisioning  
<br>

    <sup>&#42;</sup>For information on the usage limitations and environment and version requirements of these vSphere CSI Driver features, 
    see [Supported Kubernetes Functionality](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-D4AAD99E-9128-40CE-B89C-AD451DA8379D.html#GUID-E59B13F5-6F49-4619-9877-DF710C365A1E__GUID-ADF6F066-9A96-4E54-8154-66519AA65B39) 
    in _Compatibility Matrices for vSphere Container Storage Plug-in_ 
    in the VMware vSphere Container Storage Plug-in documentation.  

<br>
For information on the vCenter, datastore, and cluster types supported by the vSphere CSI Driver, see 
[vSphere Functionality Supported by vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-5B7955AA-E720-4C73-8330-1C34A0B054B3.html) 
 in the VMware vSphere Container Storage Plug-in documentation.  

For information on the scaling limitations of the vSphere CSI Driver, see 
[Configuration Maximums for vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-C0350554-F5DB-4C27-9786-720AC0F0B28A.html) 
 in the VMware vSphere Container Storage Plug-in documentation.  


<br>
## <a id='configure-cns'></a>Customize Your CNS Configuration

To customize your CNS configuration:  

* [Create a Cluster with Customized File Volume Parameters](#file-volumes-create)  
* [Modify a Cluster with Customized File Volume Parameters](#file-volumes-modify)  
* [Remove File Volume Parameters from a Cluster](#file-volumes-remove)  

### <a id='file-volumes-prereqs'></a>Prerequisites 

To use file volumes, you must enable vSAN File Services in the vSphere vCenter. 
For information about enabling vSAN File Services, see 
[Configure File Services](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vsan.doc/GUID-CA9CF043-9434-454E-86E7-DCA9AD9B0C09.html) 
in the VMware vSphere documentation.  


<br>
### <a id='file-volumes-create'></a>Create a Cluster with Customized File Volume Parameters

<br>
## <a id='create-file-volumes'></a>Customize vSphere File Volumes

To create, modify or remove a customized vSphere file volume:  

* [Create a Cluster with Customized File Volume Parameters](#file-volumes-create)  
* [Modify a Cluster with Customized File Volume Parameters](#file-volumes-modify)  
* [Remove File Volume Parameters from a Cluster](#file-volumes-remove)  

### <a id='file-volumes-prereqs'></a>Prerequisites 

To use file volumes, you must enable vSAN File Services in the vSphere vCenter. 
For information about enabling vSAN File Services, see 
[Configure File Services](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vsan.doc/GUID-CA9CF043-9434-454E-86E7-DCA9AD9B0C09.html) 
in the VMware vSphere documentation.  


<br>
### <a id='file-volumes-create'></a>Create a Cluster with Customized File Volume Parameters

To create a new cluster with a vSphere file volume:  

1. Create a JSON or YAML formatted volume configuration file containing the following:  

    ```
    {
      "target_vsan_fileshare_datastore_urls": "DS-URLS",
      "csi_datacenters": "DATA-CENTER-LIST",
      "net_permissions": [
        {
          "name": "PERMISSION-NAME",
          "ips": "IP-ADDRESS",
          "permissions": "PERMISSION",
          "rootsquash": "ACCESS-LEVEL"
        },
        {
          "name": "PERMISSION-NAME",
          "ips": "IP-ADDRESS",
          "permissions": "PERMISSION",
          "rootsquash": "ACCESS-LEVEL"
        }
      ]
    }
    ```
    
    Where:  
    
    * `DS-URLS` is a comma-separated list of datastores for deploying file share volumes. 
    For example: `"ds:///vmfs/volumes/vsan:52635b9067079319-95a7473222c4c9cd/"`.  
    * `DATA-CENTER-LIST` (Optional) is a comma-separated list of data centers to deploy file volumes to. 
    For more information, see 
    [File Volume DataStores Configuration](#file-volumes-params-datastores) below.  
    * `PERMISSION-NAME` is your name for a NetPermission.  
    * `IP-ADDRESS` is the IP range or IP subnet affected by a NetPermission restriction.  
    * `PERMISSION` is the access permission to the file share volume for a NetPermission restriction.  
    * `ACCESS-LEVEL` is the security access level for the file share volume for a NetPermission restriction.  
    <% if vars.product_version == "COMMENTED"  %>
    `"disable-vsphere-csi"`:  * `DEACTIVATE-CSI` (Optional) is a toggle to deactivate vSphere CSI Driver support. 
    Accepts Boolean values `"false"` and `"true"`. Default is `"false"`.  
    <% end %>

    For information, see [File Volume Configuration](#file-volumes-params) below.  
    
1. To create a cluster with attached file volumes:

    ```
    tkgi create-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```
    
    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  

    For example:
    <pre class="terminal">
    $ tkgi create-cluster demo -e demo.cluster --plan Small --config-file ./conf1.json
    </pre>


<br>
### <a id='file-volumes-modify'></a>Modify a Cluster with Customized File Volume Parameters

To modify an existing cluster with a vSphere file volume:  

1. Create a file volume configuration file. For information, see [File Volume Configuration](#file-volumes-params) below.   
1. To update your cluster with file volumes:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  


<br>
### <a id='file-volumes-remove'></a>Remove File Volume Parameters from a Cluster

To remove a vSphere file volume configuration from a cluster:  

1. Create a file volume configuration file containing either the `disable_target_vsan_fileshare_datastore_urls` or `disable_net_permissions`
parameters set to `true` to disable an existing file volume parameter.  
<br>
    For more information, see [File Volume Configuration](#file-volumes-params) below.  
    
1. To remove the configured file volume parameter from your cluster:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  

<%# Examples: https://confluence.eng.vmware.com/pages/viewpage.action?spaceKey=PKS&title=Detailed+design+document+for+supporting+file+volume+specific+configurations #%>

<br>
### <a id='file-volumes-params'></a>File Volume Configuration

Create a JSON or YAML formatted File Volume configuration file to enable or disable vSphere file volume support.  

For example:  

* The following configuration enables all File Volume features:  

    ```
    {
      "target_vsan_fileshare_datastore_urls": "ds:///vmfs/volumes/vsan:52635b9067079319-95a7473222c4c9cd/",
      "csi_datacenters": "kubo-dc1,kubo-dc2",
      "net_permissions": [
        {
          "name": "demo1",
          "ips": "192.168.0.0/16",
          "permissions": "READ_WRITE",
          "rootsquash": false
        },
        {
          "name": "demo2",
          "ips": "10.0.0.0/8",
          "permissions": "READ_ONLY",
          "rootsquash": false
        }
      ]
    }
    ```
    
* The following configuration disables File Volume features:  

    ```
    {
      "disable_target_vsan_fileshare_datastore_urls": true,
      "disable_net_permissions": true
    }
    ```
    
<br>
#### <a id='file-volumes-params-datastores'></a>File Volume DataStores Configuration

The following are accepted Datastore URLs parameters:  

<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>csi_datacenters</td>
        <td>string<br>Optional</td>
        <td>A comma-separated list of data centers to deploy file volumes to. 
            <br>Default Value: The data center defined on the <%= vars.k8s_runtime_abbr %> tile 
            as <strong>Kubernetes Cloud Provider</strong> > <strong>Datacenter Name</strong>. 
            <br>Example: <code>"kubo-dc1,kubo-dc2"</code>. 
            <br><strong>Note</strong>: Required when the Topology feature is enabled in a multi-data center environment. 
        </td>
    </tr>
    <tr>
        <td>disable_target_vsan_fileshare_datastore_urls</td>
        <td>Boolean</td>
        <td>Disable the target_vsan_fileshare_datastore_urls.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
    <tr>
        <td>target_vsan_fileshare_datastore_urls</td>
        <td>string</td>
        <td>A comma separated list of datastores for deploying file share volumes.</td>
    </tr>

</table>


#### <a id='file-volumes-params-netperm'></a>File Volume NetPermissions Object Configuration

The following are accepted NetPermissions objects:  
<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>net_permissions</td>
        <td>Array</td>
        <td>Properties defining a NetPermissions object.</td>
    </tr>
    <tr>
        <td>disable_net_permissions</td>
        <td>Boolean</td>
        <td>Disable the net_permissions.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
</table>  

The following are supported NetPermissions object parameters:  
<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>name</td>
        <td>string</td>
        <td>Name of the NetPermission object.</td>
    </tr>
    <tr>
        <td>ips</td>
        <td>string</td>
        <td>IP range or IP subnet affected by the NetPermission restrictions.<br>Default Value: <code>"*"</code>.</td>
    </tr>
    <tr>
        <td>permissions</td>
        <td>string</td>
        <td>Access permission to the file share volume.<br>Values: <code>"READ_WRITE"</code>, <code>"READ_ONLY"</code>, <code>"NO_ACCESS"</code>.<br>Default Value: <code>"READ_WRITE"</code>.</td>
    </tr>
    <tr>
        <td>rootsquash</td>
        <td>Boolean</td>
        <td>Security access level for the file share volume.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
</table>

For more information on NetPermissions object parameters, 
see [Procedure](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-BFF39F1D-F70A-4360-ABC9-85BDAFBE8864.html#procedure) 
in _Create a Kubernetes Secret for vSphere Container Storage Plug-in_.  

<%#FROM Confluence:  PKS Core pks-api/spec.yaml: https://confluence.eng.vmware.com/pages/viewpage.action?spaceKey=PKS&title=Detailed+design+document+for+supporting+file+volume+specific+configurations #%>
<br>
## <a id='use-cns'></a> Create or Use CNS Block Volumes

To dynamically provision a block volume using the vSphere CSI Driver:  

1. [Create a vSphere Storage Class](#create-storage)
1. [Create a PersistentVolumeClaim](#persistent-volumes-create)
1. [Create Workloads Using Persistent Volumes](#persistent-volumes-workloads)

For more information on vSphere CSI Driver configuration, see the `example/vanilla-k8s-block-driver` configuration 
for the CSI driver version you are using 
in [vsphere-csi-driver](https://github.com/kubernetes-sigs/vsphere-csi-driver/) in the VMware kubernetes-sigs GitHub repo.  


<br>
### <a id='create-storage'></a>Create a vSphere Storage Class

To create a vSphere Storage Class:

1. Open vCenter.
1. Open the vSAN Datastore Summary pane.

    ![vSAN Datastore Summary pane in vCenter](images/vsphere/datastore.png)

1. Determine the `datastoreurl` value for your Datastore.  
1. Create the following YAML:

    ```
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: demo-sts-storageclass
      annotations:
          storageclass.kubernetes.io/is-default-class: "true"
    provisioner: csi.vsphere.vmware.com
    allowVolumeExpansion: ALLOW-EXPANSION
    parameters:
      datastoreurl: "DATASTORE-URL"
    ```

    Where:  

    * `ALLOW-EXPANSION` defines whether the cluster's persistent volume size is either resizable or static. 
    Set to `true` for resizable and `false` for static size.  
    * `DATASTORE-URL` is the URL to your Datastore. 
    For a non-vSAN datastore, the `datastoreurl` value looks like 
    `ds:///vmfs/volumes/5e66e525-8e46bd39-c184-005056ae28de/`.  
<br>
    For example:

    ```
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: demo-sts-storageclass
      annotations:
          storageclass.kubernetes.io/is-default-class: "true"
    provisioner: csi.vsphere.vmware.com
    allowVolumeExpansion: true
    parameters:
      datastoreurl: "ds:///vmfs/volumes/vsan:52d8eb4842dbf493-41523be9cd4ff7b7/"
    ```
For more information about StorageClass, see [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) in the Kubernetes documentation.



<br>
### <a id='persistent-volumes-create'></a>Create a PersistentVolumeClaim

To create a Persistent Volume using the vSphere CSI Driver:

1. Create a Storage Class. For more information, see [Create a vSphere Storage Class](#create-storage) below.  
1. To apply the StorageClass configuration:
    ```
    kubectl apply -f CONFIG-FILE
    ```
    Where `CONFIG-FILE` is the name of your StorageClass configuration file. 
1. Create the PersistentVolumeClaim configuration for the file volume.
For information about configuring a PVC, see [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) in the Kubernetes documentation.      
<br>
<% if vars.product_version == "COMMENTED"  %>
     <%# (Note only for Ollie: When the PVC is created then the corresponding PV will be created automatically, but could be delayed based on StorageClass config)
     FROM github:  https://github.com/kubernetes-sigs/vsphere-csi-driver/tree/master/example/vanilla-k8s-block-driver
     Use example of example-pvc.yaml: https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/master/example/vanilla-k8s-block-driver/example-pvc.yaml #%>
<% end %>
    For example:  

    ```
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: example-vanilla-block-pvc
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 5Gi
      storageClassName: example-vanilla-block-sc
    ```
1. To apply the PVC configuration:  

    ```
    kubectl apply -f CONFIG-FILE 
    ```

    Where `CONFIG-FILE` is the name of your PVC configuration file.  


<br>
### <a id='persistent-volumes-workloads'></a>Create Workloads Using Persistent Volumes

1. Create a Pod configuration file containing `volumeMounts` and `volumes` parameters.  
<br>
    For example:  

    ```
    apiVersion: v1
    kind: Pod
    metadata:
      name: example-vanilla-block-pod
    spec:
      containers:
        - name: test-container
          image: gcr.io/google_containers/busybox:1.24
          command: ["/bin/sh", "-c", "echo 'hello' > /mnt/volume1/index.html  && chmod o+rX /mnt /mnt/volume1/index.html && while true ; do sleep 2 ; done"]
          volumeMounts:
            - name: test-volume
              mountPath: /mnt/volume1
      restartPolicy: Never
      volumes:
        - name: test-volume
          persistentVolumeClaim:
            claimName: example-vanilla-block-pvc
    ```
    <%# example-pod.yaml  https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/master/example/vanilla-k8s-block-driver/example-pod.yaml #%>

1. To apply the Pod configuration to your workload:  

    ```
    kubectl apply -f CONFIG-FILE 
    ```

    Where `CONFIG-FILE` is the name of your configuration file.  

For more information and examples of Pod configurations, see the `example` configurations 
for the CSI driver version you are using 
in [vsphere-csi-driver](https://github.com/kubernetes-sigs/vsphere-csi-driver/) in the VMware kubernetes-sigs GitHub repo.


<br>
## <a id='vsphere-topology-provisioning'></a>Customize a Cluster with vSphere Topology-Aware Volume Provisioning

<%= vars.k8s_runtime_abbr %> supports the vSphere Container Storage Plug-in's topology-aware volume provisioning features.  

For more information on volume provisioning features, see [Allowed Topologies](https://kubernetes.io/docs/concepts/storage/storage-classes/#allowed-topologies) in the Kubernetes documentation 
and [Topology-Aware Volume Provisioning](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-61646244-E24F-4E7E-AB1A-F95B5A5DD518.html) 
in the VMware vSphere Container Storage Plug-in documentation.  

<br>
### <a id='overview-topology'></a>Topology Overview 

<%= vars.k8s_runtime_abbr %> supports clusters with topology-aware volume provisioning.  

To create a cluster with topology-aware volume provisioning:  

1. [Prepare for Topology](#prepare-for-topology)  
1. See [Guidelines and Best Practices for Deployment with Topology](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-162E7582-723B-4A0F-A937-3ACE82EAFD31.html#guidelines-and-best-practices-for-deployment-with-topology-0) 
    in _Deploying vSphere Container Storage Plug-in with Topology_ in the VMware vSphere Container Storage Plug-in documentation.  
1. [Create a Cluster with Topology](#create-topology)  

<br>
To manage a cluster configured with topology-aware volume provisioning:  

1. [Prepare for Topology](#prepare-for-topology)  
1. See [Guidelines and Best Practices for Deployment with Topology](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-162E7582-723B-4A0F-A937-3ACE82EAFD31.html#guidelines-and-best-practices-for-deployment-with-topology-0) 
    in _Deploying vSphere Container Storage Plug-in with Topology_ in the VMware vSphere Container Storage Plug-in documentation.  
1. [Manage Clusters with Topology-Aware Volumes](#manage-topology)  


<p class="note"><strong>Note</strong>: You cannot add topology-aware volume provisioning to an existing cluster within <%= vars.k8s_runtime_abbr %>.
</p>

<br>
### <a id='prepare-for-topology'></a>Prepare for Topology

Before creating a new cluster with Topology-aware volume provisioning:  

1. Verify your environment meets the requirements listed in [Topology Limitations and Prerequisites](#prereqs-topology) below.  
1. Review the vSphere CSI Topology deployment recommendations. For more information, see 
[Guidelines and Best Practices for Deployment with Topology](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-162E7582-723B-4A0F-A937-3ACE82EAFD31.html#guidelines-and-best-practices-for-deployment-with-topology-0) 
in _Deploying vSphere Container Storage Plug-in with Topology_ in the VMware vSphere Container Storage Plug-in documentation.  
1. Create vSphere Center categories and tags as described in 
[Procedures](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-162E7582-723B-4A0F-A937-3ACE82EAFD31.html#procedure-5) 
in _Deploying vSphere Container Storage Plug-in with Topology_ in the VMware vSphere Container Storage Plug-in documentation.  

    
For more information on creating vSphere Center tags and categories, 
see [Create, Edit, or Delete a Tag Category](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vcenterhost.doc/GUID-BA3D1794-28F2-43F3-BCE9-3964CB207FB6.html) 
in the VMware vSphere documentation.  


<br>
### <a id='prereqs-topology'></a>Topology Limitations and Prerequisites 

In <%= vars.k8s_runtime_abbr %> you can create a new cluster with topology-aware volume provisioning enabled. 
You cannot add topology-aware volume provisioning to an existing cluster.

<%= vars.k8s_runtime_abbr %> support for Topology-aware volume provisioning requires:

* The **vSphere CSI Driver Integration** option must be enabled on the <%= vars.k8s_runtime_abbr %> tile. 
For more information, see [Storage](installing-vsphere.html#storage-config) in installing <%= vars.k8s_runtime_abbr %> on vSphere.  

* You have created vSphere CSI topology categories and tags in your vSphere environment. 
For more information, see [Prepare for Topology](#prepare-for-topology) below.  

* You have prepared your environment as described in the vSphere CSI Topology deployment recommendations. For more information, see 
[Guidelines and Best Practices for Deployment with Topology](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-162E7582-723B-4A0F-A937-3ACE82EAFD31.html#guidelines-and-best-practices-for-deployment-with-topology-0) 
in _Deploying vSphere Container Storage Plug-in with Topology_ in the VMware vSphere Container Storage Plug-in documentation.  

* The topology zone tags you create on your vSphere Client must be consistent with the existing AZs created in BOSH. 
Create topology zone tags on your vSphere Client using only AZ names existing for BOSH.  

* The topology feature does not support clusters with a Compute Profile that includes AZ settings.

<br>
### <a id='create-topology'></a>Create a Cluster with Topology

To create a new cluster with a vSphere Topology configuration:  

1. Create a JSON or YAML configuration file containing the following:  

    ```
    {
      "csi_topology_labels": {
        "topology_categories": "REGION-TAG,ZONE-TAG"
      }
    }
    ```
    
    Where:  
    
    * `REGION-TAG` is the vSphere Center region tag you created in [Prepare for Topology](#prepare-for-topology) above.  
    * `ZONE-TAG` is one of the vSphere Center zone tags you created in [Prepare for Topology](#prepare-for-topology) above.  

    For example:  

    ```
    {
      "csi_topology_labels": {
        "topology_categories": "k8s-region,k8s-zone"
      }
    }
    ```
    
    For more information, see 
    [Guidelines and Best Practices for Deployment with Topology](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-162E7582-723B-4A0F-A937-3ACE82EAFD31.html#guidelines-and-best-practices-for-deployment-with-topology-0) 
    in _Deploying vSphere Container Storage Plug-in with Topology_ in the VMware vSphere Container Storage Plug-in documentation.  
    
1. To create a cluster with Topology-aware volume provisioning:

    ```
    tkgi create-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```
    
    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  

    For example:
    <pre class="terminal">
    $ tkgi create-cluster demo -e demo.cluster --plan Small --config-file ./conf1.json
    </pre>


<br>
### <a id='manage-topology'></a>Manage Clusters with Topology-Aware Volumes

As you manage your clusters with topology-aware volume provisioning enabled, note the following limitations on existing clusters.  

When running `tkgi update-cluster` on a cluster created with a topology-aware volume:  

* You must use the same `csi_topology_labels` configuration that was used during cluster creation.  

* You cannot add or remove topology-aware volume provisioning from the cluster. 
<%#     If you must add or remove topology-aware volume provisioning from an existing cluster, see     [Guidelines and Best Practices for Deployment with Topology](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-162E7582-723B-4A0F-A937-3ACE82EAFD31.html#guidelines-and-best-practices-for-deployment-with-topology-0)     in _Deploying vSphere Container Storage Plug-in with Topology_     in the VMware vSphere Container Storage Plug-in documentation.    #%>

## <a id='manage-cns'></a>* Customize and Manage vSphere CNS 

To configure or manage you vSphere CSI Driver:  

* [Configure CNS Data Centers](#cns-datacenters)  
* [Switch From the Manually Installed vSphere CSI Driver to the Automatic CSI Driver](#uninstall-csi)  
* [Migrate an In-Tree vSphere Storage Volume to the vSphere CSI Driver](#migrate-to-csi)  


<br>
### <a id='cns-datacenters'></a>Configure CNS Data Centers

 To configure CNS for a multi-data center environment:  
 
 
1. Create a JSON or YAML formatted volume configuration file containing the following:  

    ```
    {
      "csi_datacenters": "DATA-CENTER-LIST"
    }
    ```
    
    Where:  
    
    * `DATA-CENTER-LIST` is a comma-separated list of vCenter data centers that must mount your CNS storage. 
    <% if vars.product_version == "COMMENTED"  %>
    `"disable-vsphere-csi"`:  * `DEACTIVATE-CSI` (Optional) is a toggle to deactivate vSphere CSI Driver support. 
    Accepts Boolean values `"false"` and `"true"`. Default is `"false"`.  
    <% end %>
    
1. To create a new cluster or update an existing cluster with your vCenter data centers:  

    * 1. To create a cluster:  
        
        ```
        tkgi create-cluster CLUSTER-NAME --config-file CONFIG-FILE  
        ```
        
        Where:  

        * `CLUSTER-NAME` is the name of your cluster.  
        * `CONFIG-FILE` is the name of your config file.  

        For example:
        <pre class="terminal">
        $ tkgi create-cluster demo -e demo.cluster --plan Small --config-file ./conf1.json
        </pre>


    * To update an existing cluster:  

        ```
        tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
        ```

        Where:  

        * `CLUSTER-NAME` is the name of your cluster.  
        * `CONFIG-FILE` is the name of your config file. 


<br>
### <a id='uninstall-csi'></a>Switch From the Manually Installed vSphere CSI Driver to the Automatic CSI Driver

<%= vars.k8s_runtime_abbr %> v1.14 does not support a manually installed vSphere CSI driver. 
If you have a cluster that uses a manually installed vSphere CSI driver, you must switch the cluster to the CSI driver deployed by <%= vars.k8s_runtime_abbr %>.  

To switch your clusters from the manually installed vSphere CSI driver to the auto-deployed driver:

1. [Prepare Before Upgrading <%= vars.k8s_runtime_abbr %>](#uninstall-csi-prepare)  
1. [Upgrade Your <%= vars.k8s_runtime_abbr %> Tile](#uninstall-csi-upgrade-tile)  
1. [Upgrade Your Clusters](#uninstall-csi-upgrade-cluster)  
1. [Remove a Manually Installed vSphere CSI Driver](#manually-remove-csi)  
1, [Manage Topology After Switching to the Automatically Deployed vSphere CSI Driver](#uninstall-csi-after-topology)  



#### <a id='uninstall-csi-prepare'></a>Prepare Before Upgrading <%= vars.k8s_runtime_abbr %>

Prepare your clusters and configurations before upgrading <%= vars.k8s_runtime_abbr %> to v1.14.0:  

1. To upgrade the manually deployed vSphere CSI driver on a cluster to v2.5.1:  

    1. Download the vSphere CSI Driver v2.5.1 YAML configuration file 
    [vsphere-csi-driver.yaml](https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/release-2.5/manifests/vanilla/vsphere-csi-driver.yaml) 
    from the vSphere CSI Driver GitHub repository.  
    1. Configure the configuration file for <%= vars.k8s_runtime_abbr %>. 
    For more information, see [Customize Your CSI Driver Configuration](https://docs.pivotal.io/tkgi/1-13/vsphere-cns-manual.html#customize-configuration) 
    in _Manually Installing the vSphere CSI Driver_ in the <%= vars.k8s_runtime_abbr %> v1.13 documentation.  
    1. Change the `"use-csinode-id"` parameter value in the configuration file from `"true"` to `"false"`:  

        ```
          "use-csinode-id": "false"
        ```

    1. To apply your customized configuration:  

        ```
        kubectl apply -f vsphere-csi-driver.yaml
        ```
    
    For more information, see [Upgrade vSphere Container Storage Plug-in of a Version 2.3.0 or Later](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-3F277B52-68CC-4125-AD0F-E7293940B4B4.html#GUID-2426D857-F3DA-41DB-9C64-7191854ACDE9__GUID-E5623816-32B8-421C-832C-01398551BEB6) 
    in _Upgrading vSphere Container Storage Plug-in_ in the VMware vSphere Container Storage Plug-in documentation.  

1. If topology-aware volume provisioning is enabled on a cluster, create a TKGI configuration file for the cluster. 
For more information, see [Manage Topology After Switching to the Automatically Deployed vSphere CSI Driver](#uninstall-csi-after-topology) below.  


#### <a id='uninstall-csi-upgrade-tile'></a>Upgrade Your <%= vars.k8s_runtime_abbr %> Tile

To upgrade your <%= vars.k8s_runtime_abbr %> tile: 

1. Download and import the <%= vars.product_tile %> v1.14.0 tile. 
For more information, see [Download and Import <%= vars.product_short %>](upgrade.html#upgrade-tile) 
in _Upgrading Tanzu Kubernetes Grid Integrated Edition_.  
1. Download and import Stemcells. 
For more information, see [Download and Import Stemcells](upgrade.html#stemcell) 
in _Upgrading Tanzu Kubernetes Grid Integrated Edition_.  
1. Deselect the **Upgrade All Clusters** errand. 
For more information, see [Verify Errand Configuration](upgrade.html#errands) 
in _Upgrading Tanzu Kubernetes Grid Integrated Edition_.  
<%#    Upgrade the <  %= vars.k8s_runtime_abbr %  > clusters to v1.14.0.  #%>
1. Enable **vSphere CSI Driver Integration** on the TKGI tile. 
For more information, see [Verify Other Configurations](upgrade.html#final-review) 
in _Upgrading Tanzu Kubernetes Grid Integrated Edition_.  
1. Select **Apply Changes**. 
For more information, see [Apply Changes to the <%= vars.product_tile %> Tile](upgrade.html#apply-changes) 
in _Upgrading Tanzu Kubernetes Grid Integrated Edition_.  
1. Complete the [After the Upgrade](upgrade.html#after-upgrade) steps as usual. 


#### <a id='uninstall-csi-upgrade-cluster'></a>Upgrade Your Clusters

To switch a cluster to the automatically deployed vSphere CSI Driver:  

1. Upgrade your <%= vars.k8s_runtime_abbr %> cluster to v1.14.0.  
1. If topology-aware volume provisioning is enabled on your cluster, 
update your cluster using the topology configuration file you created in 
[Prepare Before Upgrading <%= vars.k8s_runtime_abbr %>](#uninstall-csi-prepare) above.  
1. Remove the manually installed CSI driver from the cluster. 
For more information, see [Remove a Manually Installed vSphere CSI Driver](#manually-remove-csi) below.  
1. To restart CSI jobs on all worker nodes:  
    
    ```
    bosh -d DEPLOYMENT ssh worker "sudo monit restart csi-node"
    bosh -d DEPLOYMENT ssh worker "sudo monit restart csi-node-registrar"
    ```
    
    Where:  
    
    * `DEPLOYMENT` is the name of the deployment.  
    
1. To verify that the CSI jobs on all control plane nodes are in a running state:  

    ```
    bosh -d DEPLOYMENT ssh master "sudo monit summary | grep csi"
    ```

    Where:  

    * `DEPLOYMENT` is the name of the deployment.  

6. If a CSI job is not in a running state, start the CSI job:  

    ```
    bosh -d DEPLOYMENT ssh NODE-VM "sudo monit start JOB-NAME"
    ```

    Where:  

    * `DEPLOYMENT` is the name of the deployment.  
    * `NODE-VM` is the control plane node VM.  
    * `JOB-NAME` is the name of the CSI job to start.  

<br>
#### <a id='manually-remove-csi'></a>Remove a Manually Installed vSphere CSI Driver

If you have a cluster that uses a manually installed vSphere CSI Driver, 
and you upgrade the cluster after your administrator has enabled automatic vSphere CSI Driver Integration,
you should remove the manually installed driver. 
While automatic vSphere CSI Driver Integration is enabled, 
<%= vars.k8s_runtime_abbr %> enables the integrated driver for a cluster after upgrading it, 
and the cluster's manually installed driver no longer functions.  

To remove a manually installed vSphere CSI driver:

1. Run the following command:  

    ```
    kubectl delete -f vsphere-csi-driver.yaml
    ```



<br>
#### <a id='uninstall-csi-after-topology'></a>Manage Topology After Switching to the Automatically Deployed vSphere CSI Driver

After switching from a manually installed vSphere CSI Driver to the <%= vars.k8s_runtime_abbr %> automatically deployed CSI Driver, 
the topology configuration must not be changed.  

Configure topology based on the manually installed vSphere CSI Driver configuration:  

* **Region and Zone Topology Labels**:  

    You must continue to use `region`, and `zone` labels if your manually deployed vSphere CSI Driver was configured using 
    the legacy `region`, and `zone` topology configuration labels.  


    Your revised cluster configuration file must include a `csi_topology_labels` parameter that assigns `region` and `zone` values.  
    
    For example, if your vSphere Secret configuration for the manually installed vSphere CSI driver included the following:  
    
    ```
    [Labels]
    region = k8s-region
    zone = k8s-zone
    ```
    
    Your new cluster configuration must include the following instead:
    
    ```
    { 
      "csi_topology_labels": { 
          "region: "k8s-region" 
          "zone": "k8s-zone" 
      } 
    }
    ```

* **topology_categories Topology Label**:  
    
    You must continue to use the `topology_categories` label if your manually deployed vSphere CSI Driver was configured using 
    the `topology_categories` topology configuration label.  

    Your revised cluster configuration file must include a `csi_topology_labels` parameter that assigns a `topology_categories` value.  
    
    For example, if your vSphere Secret configuration for the manually installed vSphere CSI driver included the following:  
    
    ```
    [Labels]
    topology-categories = "k8s-region, k8s-zone"

    ```
    
    Your new cluster configuration must include the following instead:  
    
    ```
    { 
      "csi_topology_labels": { 
        "topology_categories": "k8s-region,k8s-zone" 
      } 
    }
    ```
    
* **Topology Disabled**:  

    You must not enable topology if topology was not enabled while using the manually deployed vSphere CSI Driver.

<br>
### <a id='migrate-to-csi'></a> Migrate an In-Tree vSphere Storage Volume to the vSphere CSI Driver

Kubernetes' support for in-tree vSphere storage volumes has been deprecated, and support will be removed in a future Kubernetes version.  

The <%= vars.k8s_runtime_abbr %> v1.15 upgrade process will automatically migrate your in-tree vSphere storage volumes to vSphere CSI. 
If you have existing clusters that use in-tree vSphere storage volumes, you can continue to use the volumes with your current version of TKGI, but 
VMware strongly recommends that you migrate your in-tree vSphere storage volumes to vSphere CSI volumes before upgrading to <%= vars.k8s_runtime_abbr %> v1.15.  

To manually migrate a cluster from an in-tree vSphere storage volume to a vSphere CSI Driver volume, 
see [Migrate In-Tree vSphere Storage Volumes to the vSphere CSI Driver](#migrate-volumes) below.  

To prepare <%= vars.k8s_runtime_abbr %> to use vSphere CSI Driver volumes by default 
and to automatically migrate clusters from in-tree vSphere storage volumes to vSphere CSI Driver volumes during the TKGI v1.15 upgrade, 
see [Prepare for Automatic Migration of Volumes from VCP to CSI](#prepare-to-migrate) below.  


<br>
#### <a id='prepare-to-migrate'></a> Prepare for Automatic Migration of Volumes from In-Tree vSphere Storage to CSI

If your existing clusters have in-tree vSphere storage volumes, you must prepare for them to be automatically migrated before upgrading to <%= vars.k8s_runtime_abbr %> 1.15.  

To prepare for automatic migration from in-tree vSphere storage volumes to vSphere CSI:  

1. Enable **vSphere CSI Drive Integration** on the <%= vars.product_tile %> tile.  For more information, 
see [Storage](installing-vsphere.html#storage) in _Installing <%= vars.k8s_runtime_abbr %> on vSphere_.  
1. (Optional) Test migrating your in-tree vSphere storage volumes to vSphere CSI volumes prior to upgrading to <%= vars.k8s_runtime_abbr %> 1.15. 
See [Migrate In-Tree vSphere Storage Volumes to the vSphere CSI Driver](#migrate-volumes) below.  
1. (Optional) To avoid a slow upgrade to <%= vars.k8s_runtime_abbr %> v1.15, migrate your in-tree vSphere storage volumes to the vSphere CSI Driver before upgrading. 
See [Migrate In-Tree vSphere Storage Volumes to the vSphere CSI Driver](#migrate-volumes) below.  

<p class="note"><strong>Note</strong>: VMware strongly recommends that you migrate your in-tree vSphere storage volumes to vSphere CSI volumes as soon as possible.
</p>

<br>
#### <a id='migrate-volumes'></a> Migrate In-Tree vSphere Storage Volumes to the vSphere CSI Driver

You can use `tkgi update-cluster` to migrate the PersistentVolume (PV) and PersistentVolumeClaim (PVC) on an existing <%= vars.k8s_runtime_abbr %> cluster 
from the In-Tree vSphere Storage Driver to the automatically installed vSphere CSI Driver.
    
<p class="note warning"><strong>Warning</strong>: Due to Known Issues in the vSphere CSI Driver, <%= vars.recommended_by %> recommends that you migrate to the vSphere CSI Driver after upgrading to <%= vars.k8s_runtime_abbr %> v1.14.1.
    For more information, see <a href="release-notes.html#1-14-0-vmdks-deleted-during-migration">VMDKs Are Deleted during Migration from In-Tree Storage to CSI</a> 
    in the <i>Release Notes</i>.
</p>

Migrating a <%= vars.k8s_runtime_abbr %> cluster from the In-Tree vSphere Storage Driver to the vSphere CSI Driver requires the following:  

* You must use <%= vars.k8s_runtime_abbr %> CLI v1.12 or later.  
* <%= vars.k8s_runtime_abbr %> automatic vSphere CSI Driver integration must be enabled. 
    For information on enabling the **vSphere CSI Driver Integration** option on the <%= vars.k8s_runtime_abbr %> tile, see [Storage](installing-vsphere.html#storage-config) in 
    _Installing <%= vars.product_short %> on vSphere_.  
* <%= vars.k8s_runtime_abbr %> must be installed on vSphere v7.0 U2 or later.  
* The cluster must be a Linux <%= vars.k8s_runtime_abbr %> cluster.  

<br>
To migrate a cluster from an In-Tree vSphere Storage Driver to the vSphere CSI Driver:  

1. Upgrade your Kubernetes cluster to the current <%= vars.k8s_runtime_abbr %> version of the <%= vars.k8s_runtime_abbr %> tile.  
1. Review and complete all relevant steps documented in the vSphere CSI Migration documentation:  

    * [Prerequisites for Installing the vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-0AB6E692-AA47-4B6A-8CEA-38B754E16567.html)  
    * [Migrating In-Tree vSphere Volumes to vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-968D421F-D464-4E22-8127-6CB9FF54423F.html#considerations-for-migration-of-intree-vsphere-volumes-0)  
    * [vSphere Container Storage Plug-in Upgrade Considerations and Guidelines](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-3F277B52-68CC-4125-AD0F-E7293940B4B4.html#vsphere-container-storage-plugin-upgrade-considerations-and-guidelines-0)  

    <p class="note warning"><strong>Warning</strong>: Before migrating to the vSphere CSI driver, 
    confirm your cluster's volume storage is configured as described in 
    <a href="https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-968D421F-D464-4E22-8127-6CB9FF54423F.html#considerations-for-migration-of-intree-vsphere-volumes-0">
    Considerations for Migration of In-Tree vSphere Volumes</a>.
    </p>
    
1. Create a configuration file containing the following:  

    ```
    {
        "enable_csi_migration": "true"
    }
    ```
1. To migrate your cluster to the vSphere CSI Driver:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  

    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of the config file you created in the preceding steps.  
    
<p class="note"><strong>Note</strong>: You cannot migrate the PV or the PVC 
    on a cluster from the vSphere CSI Driver to the In-Tree vSphere Storage Driver.
</p>
