---
title: Deploying and Managing Cloud Native Storage (CNS) on vSphere
owner: TKGI
---

This topic describes how to use the vSphere Container Storage Interface (CSI) Driver 
that is automatically installed to clusters by <%= vars.product_full %> (<%= vars.k8s_runtime_abbr %>) on vSphere.  

If your <%= vars.k8s_runtime_abbr %> environment is on vSphere and your administrator has not enabled automatic vSphere CSI Driver installation, 
you must manually install a vSphere CSI Driver on your clusters. For more information, 
see [Manually Installing the vSphere CSI Driver](vsphere-cns-manual.html).  

## <a id='overview'></a>Overview

vSphere Cloud Native Storage (CNS) provides comprehensive data management for stateful, containerized apps,
enabling apps to survive restarts and outages.
Stateful containers can use vSphere storage primitives such as standard volume, persistent volume, and dynamic provisioning, 
independent of VM and container lifecycle.  

You can install vSphere CNS on <%= vars.k8s_runtime_abbr %>-provisioned clusters by configuring <%= vars.k8s_runtime_abbr %> 
to automatically install a vSphere CSI Driver. 
To enable automatic CSI driver installation on your clusters, 
see [Storage](installing-vsphere.html#storage-config) in _Installing <%= vars.k8s_runtime_abbr %> on vSphere_.  

When automatic vSphere CSI Driver installation is enabled, your clusters 
use your tile **Kubernetes Cloud Provider** storage settings as the default vSphere CNS configuration.  

You can customize, deploy and manage vSphere CNS volumes using the vSphere CSI Driver:  

* To customize file volumes, see [Customize vSphere File Volumes](#create-file-volumes) below.
* To use and customize CNS Volumes, see [Create or Use CNS Block Volumes](#use-cns) below.

The automatically deployed vSphere CSI Driver supports high availability (HA) configurations. HA support 
is automatically enabled on clusters with multiple control plane nodes and uses only one active CSI Controller.  

Use the vSphere client to review your cluster storage volumes and their backing virtual disks, and to 
set a storage policy on your storage volumes or monitor policy compliance. 
vSphere storage backs up your cluster volumes.  

<p class="note"><strong>Note</strong>: If you have an existing cluster with a manually installed vSphere CSI driver 
and your administrator has enabled automatic vSphere CSI Driver installation, you must uninstall the manually installed vSphere CSI Driver 
from your cluster. 
For more information, see <a href="#uninstall-csi">Uninstall a Manually Installed vSphere CSI Driver</a> below.
</p>


For more information about VMware CNS, see [Getting Started with VMware Cloud Native Storage](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.storage.doc/GUID-CF1D7196-E49C-4430-8C50-F8E35CAAE060.html).  

For more information about using the Kubernetes CSI Driver, see
[Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) in the Kubernetes documentation.  


### <a id='supported-feature'></a> vSphere CSI Driver Supported Features and Requirements

The vSphere CSI Driver supports different features depending on driver version, environment and storage type.  

<%= vars.k8s_runtime_abbr %> supports only the following vSphere CSI Driver features:  

* Enhanced Object Health in UI for vSAN Datastores  
* Dynamic Block PV support<sup>&#42;</sup>  
* Dynamic Virtual Volume (vVOL) PV support  
* Static PV Provisioning  
* Kubernetes Multi-node Control Plane support  
* Encryption support via VMcrypt<sup>&#42;</sup>  
* Dynamic File PV support<sup>&#42;</sup>  
<br>

    <sup>&#42;</sup>For information on the usage limitations and environment and version requirements of these vSphere CSI Driver features, 
    see [Functionality Supported by vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-E59B13F5-6F49-4619-9877-DF710C365A1E.html#functionality-supported-by-vsphere-container-storage-plugin-0) 
    in _Supported Kubernetes Functionality and Limitations_ in the VMware vSphere Container Storage Plug-in documentation.  

<br>
For information on the vCenter, datastore, and cluster types supported by the vSphere CSI Driver, see 
[vSphere Functionality Supported by vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-5B7955AA-E720-4C73-8330-1C34A0B054B3.html) 
 in the VMware vSphere Container Storage Plug-in documentation.  

For information on the scaling limitations of the vSphere CSI Driver, see 
[Configuration Maximums for vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-C0350554-F5DB-4C27-9786-720AC0F0B28A.html) 
 in the VMware vSphere Container Storage Plug-in documentation.  



## <a id='create-file-volumes'></a>Customize vSphere File Volumes

To create, modify or remove a customized vSphere file volume:  

* [Create a Cluster With Customized File Volume Parameters](#file-volumes-create)  
* [Modify a Cluster With Customized File Volume Parameters](#file-volumes-modify)  
* [Remove File Volume Parameters from a Cluster](#file-volumes-remove)  

### <a id='file-volumes-prereqs'></a>Prerequisites 

To use file volumes, you must enable vSAN File Services in the vSphere vCenter. 
For information about enabling vSAN File Services, see 
[Configure File Services](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vsan.doc/GUID-CA9CF043-9434-454E-86E7-DCA9AD9B0C09.html) 
in the VMware vSphere documentation.  


### <a id='file-volumes-create'></a>Create a Cluster With Customized File Volume Parameters

To create a new cluster with a vSphere file volume:  

1. Create a file volume configuration file. For information, see [File Volume Configuration](#file-volumes-params) below.  
1. To create a cluster with attached file volumes:

    ```
    tkgi create-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```
    
    Where:  
    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  

    For example:
    <pre class="terminal">
    $ tkgi create-cluster demo -e demo.cluster --plan Small --config-file ./conf1.json
    </pre>

### <a id='file-volumes-modify'></a>Modify a Cluster With Customized File Volume Parameters

To modify an existing cluster with a vSphere file volume:  

1. Create a file volume configuration file. For information, see [File Volume Configuration](#file-volumes-params) below.   
1. To update your cluster with file volumes:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  
    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  


### <a id='file-volumes-remove'></a>Remove File Volume Parameters from a Cluster

To remove a vSphere file volume configuration from a cluster:  

1. Create a file volume configuration file containing either the `disable_target_vsan_fileshare_datastore_urls` or `disable_net_permissions`
parameters set to `true` to disable an existing file volume parameter. 
For information, see [File Volume Configuration](#file-volumes-params) below.  
<br>
    For example:  

    ```
    {
        "disable_target_vsan_fileshare_datastore_urls": true,
        "disable_net_permissions": true
    }
    ```
1. To remove the configured file volume parameter from your cluster:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  
    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of your config file.  

<%# Examples: https://confluence.eng.vmware.com/pages/viewpage.action?spaceKey=PKS&title=Detailed+design+document+for+supporting+file+volume+specific+configurations #%>

### <a id='file-volumes-params'></a>File Volume Configuration

To customize a vSphere file volume, create a JSON or YAML formatted file volume configuration file using the supported file volume parameters below.  

For example:  

```
{
  "target_vsan_fileshare_datastore_urls": "ds:///vmfs/volumes/vsan:52635b9067079319-95a7473222c4c9cd/",
  "net_permissions": [
    {
      "name": "demo1",
      "ips": "192.168.0.0/16",
      "permissions": "READ_WRITE",
      "rootsquash": false
    },
    {
      "name": "demo2",
      "ips": "10.0.0.0/8",
      "permissions": "READ_ONLY",
      "rootsquash": false
    }
  ]
}
```

The following are accepted File Volume configuration file parameters:

<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>target_vsan_fileshare_datastore_urls</td>
        <td>string</td>
        <td>A comma separated list of datastores for deploying file share volumes.</td>
    </tr>
    <tr>
        <td>disable_target_vsan_fileshare_datastore_urls</td>
        <td>Boolean</td>
        <td>Disable the target_vsan_fileshare_datastore_urls.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
    <tr>
        <td>net_permissions</td>
        <td>Array</td>
        <td>Properties defining a NetPermissions object.</td>
    </tr>
    <tr>
        <td>disable_net_permissions</td>
        <td>Boolean</td>
        <td>Disable the net_permissions.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
</table>

The following are supported NetPermission object configuration file parameters:

<table>
    <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>name</td>
        <td>string</td>
        <td>Name of the NetPermission object.</td>
    </tr>
    <tr>
        <td>ips</td>
        <td>string</td>
        <td>IP range or IP subnet affected by the NetPermission restrictions.<br>Default Value: <code>"*"</code>.</td>
    </tr>
    <tr>
        <td>permissions</td>
        <td>string</td>
        <td>Access permission to the file share volume.<br>Values: <code>"READ_WRITE"</code>, <code>"READ_ONLY"</code>, <code>"NO_ACCESS"</code>.<br>Default Value: <code>"READ_WRITE"</code>.</td>
    </tr>
    <tr>
        <td>rootsquash</td>
        <td>Boolean</td>
        <td>Security access level for the file share volume.<br>Values: <code>true</code>, <code>false</code>.<br>Default Value: <code>false</code>.</td>
    </tr>
</table>


<%#FROM Confluence:  PKS Core pks-api/spec.yaml: https://confluence.eng.vmware.com/pages/viewpage.action?spaceKey=PKS&title=Detailed+design+document+for+supporting+file+volume+specific+configurations #%>

## <a id='use-cns'></a> Create or Use CNS Block Volumes

To dynamically provision a block volume using the vSphere CSI Driver:  

1. [Create a vSphere Storage Class](#create-storage)
1. [Create a PersistentVolumeClaim](#persistent-volumes-create)
1. [Create Workloads Using Persistent Volumes](#persistent-volumes-workloads)

For more information on vSphere CSI Driver configuration, see the `example/vanilla-k8s-block-driver` configuration 
for the CSI driver version you are using 
in [vsphere-csi-driver](https://github.com/kubernetes-sigs/vsphere-csi-driver/) in the VMware kubernetes-sigs GitHub repo.  


### <a id='create-storage'></a>Create a vSphere Storage Class

To create a vSphere Storage Class:

1. Open vCenter.
1. Open the vSAN Datastore Summary pane.

    ![vSAN Datastore Summary pane in vCenter](images/vsphere/datastore.png)

1. Determine the `datastoreurl` value for your Datastore.  
1. Create the following YAML:

    ```
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: demo-sts-storageclass
      annotations:
          storageclass.kubernetes.io/is-default-class: "true"
    provisioner: csi.vsphere.vmware.com
    allowVolumeExpansion: ALLOW-EXPANSION
    parameters:
      datastoreurl: "DATASTORE-URL"
    ```

    Where:
    * `ALLOW-EXPANSION` defines whether the cluster's persistent volume size is either resizable or static. 
    Set to `true` for resizable and `false` for static size.  
    * `DATASTORE-URL` is the URL to your Datastore. 
    For a non-vSAN datastore, the `datastoreurl` value looks like 
    `ds:///vmfs/volumes/5e66e525-8e46bd39-c184-005056ae28de/`.<br>  

    For example:

    ```
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: demo-sts-storageclass
      annotations:
          storageclass.kubernetes.io/is-default-class: "true"
    provisioner: csi.vsphere.vmware.com
    allowVolumeExpansion: true
    parameters:
      datastoreurl: "ds:///vmfs/volumes/vsan:52d8eb4842dbf493-41523be9cd4ff7b7/"
    ```
For more information about StorageClass, see [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) in the Kubernetes documentation.




### <a id='persistent-volumes-create'></a>Create a PersistentVolumeClaim

To create a Persistent Volume using the vSphere CSI Driver:

1. Create a Storage Class. For more information, see [Create a vSphere Storage Class](#create-storage) below.  
1. To apply the StorageClass configuration:
    ```
    kubectl apply -f CONFIG-FILE
    ```
    Where `CONFIG-FILE` is the name of your StorageClass configuration file. 
1. Create the PersistentVolumeClaim configuration for the file volume.
For information about configuring a PVC, see [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) in the Kubernetes documentation.      
<br>
     <%# (Note only for Ollie: When the PVC is created then the corresponding PV will be created automatically, but could be delayed based on StorageClass config)
     FROM github:  https://github.com/kubernetes-sigs/vsphere-csi-driver/tree/master/example/vanilla-k8s-block-driver
     Use example of example-pvc.yaml: https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/master/example/vanilla-k8s-block-driver/example-pvc.yaml #%>
    For example:

    ```
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: example-vanilla-block-pvc
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 5Gi
      storageClassName: example-vanilla-block-sc
    ```
1. To apply the PVC configuration:  

    ```
    kubectl apply -f CONFIG-FILE 
    ```

    Where `CONFIG-FILE` is the name of your PVC configuration file.  


### <a id='persistent-volumes-workloads'></a>Create Workloads Using Persistent Volumes

1. Create a Pod configuration file containing `volumeMounts` and `volumes` parameters.  
<br>
    For example:

    ```
    apiVersion: v1
    kind: Pod
    metadata:
      name: example-vanilla-block-pod
    spec:
      containers:
        - name: test-container
          image: gcr.io/google_containers/busybox:1.24
          command: ["/bin/sh", "-c", "echo 'hello' > /mnt/volume1/index.html  && chmod o+rX /mnt /mnt/volume1/index.html && while true ; do sleep 2 ; done"]
          volumeMounts:
            - name: test-volume
              mountPath: /mnt/volume1
      restartPolicy: Never
      volumes:
        - name: test-volume
          persistentVolumeClaim:
            claimName: example-vanilla-block-pvc
    ```
    <%# example-pod.yaml  https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/master/example/vanilla-k8s-block-driver/example-pod.yaml #%>

1. To apply the Pod configuration to your workload:  

    ```
    kubectl apply -f CONFIG-FILE 
    ```

    Where `CONFIG-FILE` is the name of your configuration file.  

For more information and examples of Pod configurations, see the `example` configurations 
for the CSI driver version you are using 
in [vsphere-csi-driver](https://github.com/kubernetes-sigs/vsphere-csi-driver/) in the VMware kubernetes-sigs GitHub repo.


## <a id='uninstall-csi'></a>Uninstall a Manually Installed vSphere CSI Driver

If your administrator has enabled automatic vSphere CSI Driver Integration and you have a cluster that uses a manually installed vSphere CSI Driver, 
the manually installed driver will no longer function after upgrading the cluster.   

To uninstall a manually installed CSI driver:

1. Confirm your <%= vars.k8s_runtime_abbr %> administrator has enabled automatic **vSphere CSI Driver Integration** on the <%= vars.k8s_runtime_abbr %> tile.
2. Upgrade your Kubernetes cluster to the <%= vars.k8s_runtime_abbr %> version of the <%= vars.k8s_runtime_abbr %> tile.
3. Remove the manually installed CSI driver from the cluster. 
For more information, see [Remove a Manually Installed vSphere CSI Driver](#manually-remove-csi) below.  
<%# 
4. Validate that CNS recognizes the existing storage.  
by completing the steps in
[Create and Manage vSphere CNS Volumes](#overview-managing) above.  
#%>
4. To restart CSI jobs, restart `csi-node-registrar` on each worker node:

    ```
    bosh -d DEPLOYMENT ssh WORKER-NODE
    sudo bash
    monit restart csi-node-registrar
    ```

    Where:  
    * `DEPLOYMENT` is the name of the deployment.
    * `WORKER-NODE` is the worker node VM.

5. To verify the CSI jobs are in running state, run the following on each control plane node: 

    ```
    bosh -d DEPLOYMENT ssh CONTROL-PLANE-NODE
    sudo bash
    monit summary | grep csi
    ```

    Where:  
    * `DEPLOYMENT` is the name of the deployment.
    * `CONTROL-PLANE-NODE` is the control plane node VM.

6. To restart a CSI job that is not in running state:  

    ```
    monit restart JOB-NAME
    ```

    Where `JOB-NAME` is the name of the CSI job to restart.  




### <a id='manually-remove-csi'></a>Remove a Manually Installed vSphere CSI Driver

If you have a cluster that uses a manually installed vSphere CSI Driver, 
and you upgrade the cluster after your administrator has enabled automatic vSphere CSI Driver Integration,
you should remove the manually installed driver. 
While automatic vSphere CSI Driver Integration is enabled, 
<%= vars.k8s_runtime_abbr %> enables the integrated driver for a cluster after upgrading it, 
and the cluster's manually installed driver no longer functions.  

To remove a manually installed vSphere CSI driver:

1. Create a manifest `remove-vsphere-csi-node-ds.yaml` that removes the CSI controller `DaemonSet`.

1. Remove the DaemonSet:

    ```
    kubectl apply -f remove-vsphere-csi-node-ds.yaml
    ```

1. Create a manifest `remove-vsphere-csi-controller-deployment.yaml` that removes the deployment and `CSIDriver` objects for the CSI controller.

1. Remove the CSI driver objects:

    ```
    kubectl apply -f remove-vsphere-csi-controller-deployment.yaml
    ```

1. Create a manifest `remove-vsphere-csi-controller-rbac.yaml` that removes the RBAC rules.

1. Remove the RBAC resource:

    ```
    kubectl apply -f remove-vsphere-csi-controller-rbac.yaml
    ```

<%#
If users manually deployed the vSphere CSI Driver previously, and they want to enable vSphere CSI Driver in TKGI 1.11 tile, 
then they must manually delete the manually deployed CSI Drive after successfully upgrading the K8S cluster to TKGI 1.11. 
Please note that the key point is the timing, in other words, 
they can't delete the manually deployed vSphere CSI Driver before upgrading the existing cluster(s); 
Instead, they should perform the operation after upgrading the existing cluster(s). 
We need to get the above info included in the document. #%>

## <a id='migrate-to-csi'></a>Migrate from VCP to the vSphere CSI Driver

You can use `tkgi update-cluster` to migrate the PersistentVolume (PV) and PersistentVolumeClaim (PVC) on an existing <%= vars.k8s_runtime_abbr %> cluster 
from VCP to the automatically installed vSphere CSI Driver.

<p class="note"><strong>Note</strong>: You cannot migrate the PV or the PVC 
    on a cluster from the vSphere CSI Driver to VCP.
</p>

Migrating a <%= vars.k8s_runtime_abbr %> cluster from VCP to the vSphere CSI Driver requires the following:  

* You must use <%= vars.k8s_runtime_abbr %> CLI v1.12 or later.  
* <%= vars.k8s_runtime_abbr %> automatic vSphere CSI Driver integration must be enabled. 
    For information on enabling the **vSphere CSI Driver Integration** option on the <%= vars.k8s_runtime_abbr %> tile, see [Storage](installing-vsphere.html#storage-config) in 
    _Installing <%= vars.product_short %> on vSphere_.  
* <%= vars.k8s_runtime_abbr %> must be installed on vSphere v7.0 U1 or later.  
* The cluster must be a Linux <%= vars.k8s_runtime_abbr %> cluster.  

<br>
To migrate a cluster from VCP to the vSphere CSI driver:

<%#1. Confirm your < %= vars.k8s_runtime_abbr % > administrator has enabled automatic **vSphere CSI Driver Integration** on the < %= vars.k8s_runtime_abbr % > tile. %>
1. Upgrade your Kubernetes cluster to the current <%= vars.k8s_runtime_abbr %> version of the <%= vars.k8s_runtime_abbr %> tile.  
1. Review and complete all relevant steps documented in the vSphere CSI Migration documentation:  
    * [Prerequisites for Installing the vSphere Container Storage Plug-in](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-0AB6E692-AA47-4B6A-8CEA-38B754E16567.html)  
    * [vSphere Container Storage Plug-in Upgrade Considerations and Guidelines](https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-3F277B52-68CC-4125-AD0F-E7293940B4B4.html#vsphere-container-storage-plugin-upgrade-considerations-and-guidelines-0)  
    * [Things to consider before turning on Migration](https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/v2.4.0/docs/book/features/vsphere_csi_migration.md#things-to-consider-before-turning-on-migration-)  

    <p class="note warning"><strong>Warning</strong>: Before migrating to the vSphere CSI driver, 
    confirm your cluster's volume storage is configured as described in 
    <a href="https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/v2.4.0/docs/book/features/vsphere_csi_migration.md#things-to-consider-before-turning-on-migration-">
    Things to consider before turning on Migration</a>.
    </p>
    
1. Create a configuration file containing the following:  

    ```
    {
        "enable_csi_migration": "true"
    }
    ```
1. To migrate your cluster to the vSphere CSI driver:

    ```
    tkgi update-cluster CLUSTER-NAME --config-file CONFIG-FILE 
    ```

    Where:  
    * `CLUSTER-NAME` is the name of your cluster.  
    * `CONFIG-FILE` is the name of the config file you created in the preceding steps. 