---
title: Using Compute Profiles
owner: TKGI
---

<%= partial 'beta-component' %>

This topic describes how to use compute profiles for Kubernetes clusters
provisioned with <%= vars.product_full %> on vSphere with NSX-T integration.

The procedures in this topic use the <%= vars.control_plane %>.

## <a id='overview'></a> Overview

Compute profiles allow you to specify which vSphere resources are used
when deploying Kubernetes clusters in a <%= vars.k8s_runtime_abbr %> deployment.
Use this feature to control where your Kubernetes clusters
are created within your virtual infrastructure.

With compute profiles, you can define Availability Zones (AZs) dynamically
instead of adding new AZs in the BOSH Director tile.
As a result, you do not need to make AZ changes to each plan
and the overall impact to the <%= vars.k8s_runtime_abbr %> control plane is smaller.

<p class="note"><strong>Note</strong>: Compute profiles only override the AZ values
specified in <%= vars.product_short %> plans.
The rest of the cluster's configuration is inherited from the plan.</p>

You define a compute profile within a JSON file, and then create clusters
that use the compute profile using the <%= vars.control_plane %>.

You can customize any number of compute profiles.

## <a id='prerequisites'></a> Prerequisites

Before you define a compute profile, you must have the following:

* A configured <%= vars.product_short %> installation on vSphere with NSX-T. 
See [Installing <%= vars.product_short %> on vSphere with NSX-T](installing-nsx-t.html).
* A <%= vars.k8s_runtime_abbr %> UAA admin access token to provide when calling the <%= vars.control_plane %>. 
For instructions that explain how to export your access token to an environment variable, see
[Export <%= vars.control_plane %> Token](login.html#tkgi-api-access).

## <a id='define'></a> Define a Compute Profile

Define a compute profile in a JSON file.

1. In a new text file, enter the parameters for the compute profile in the following format:

    ```json
    {
        "name" : "PROFILE-NAME",
        "description" : "PROFILE-DESCRIPTION",
        "parameters" : {
            "azs": [{
                "name": "AZ-NAME",
                "cpi": "CPI-NAME",
                "cloud_properties": {
                    "datacenters": [{
                        "name": "DC-NAME",
                        "clusters": [{
                            "CLUSTER-NAME": {
                                "resource_pool": "RESOURCE-POOL-NAME"
                            }
                        }]     
                    }]
                }
            }],
            "master_azs": ["AZ-NAME"],
            "worker_azs": ["AZ-NAME"]
        }
    }
    ```

    Where:
    - `PROFILE-NAME` is the name of the compute profile that you want to define. Enter a string value up to 26 characters long. For example, `dev`.
    - (Optional) `PROFILE-DESCRIPTION` describes the compute profile.
    - `AZ-NAME` is a name for the availability zone (AZ) where you want to deploy cluster VMs. For example, `z1`.     
       <p class="note"><strong>Note</strong>: If you define multiple AZs in the <code>azs</code> array, you can specify different AZs for worker node VMs and master node VMs.</p>
    - `CPI-NAME` is the BOSH CPI ID of your <%= vars.product_short %> deployment. For instructions on how to obtain the `CPI-NAME`, see [Retrieve the BOSH CPI ID](#retrieve-cpi-id). For example, `abc012abc345abc567de`.
    - `DC-NAME` is the name of your datacenter as it appears in Ops Manager and your cloud provider console. For example, `dc-east`. For additional cloud properties related to AZs, see the [vSphere CPI AZs](https://bosh.io/docs/vsphere-cpi/#azs) section of the BOSH documentation.
    - `CLUSTER-NAME` is the name that you want to give your cluster.
    - `RESOURCE-POOL-NAME` is the name of the resource pool where you want to deploy your cluster.

    For example, this compute profile shows one AZ for one cluster assigned to the `resource_pool` named `my-res-pool`:

    ```json
    {
        "name": "dev",
        "description": "For development clusters",
        "parameters": {
            "azs": [{
                "cpi": "abc012abc345abc567des",
                "name": "z1",
                "cloud_properties": {
                    "datacenters": [{
                        "name": "my-dc",
                        "clusters": [{
                            "my-vsphere-cluster": {
                                "resource_pool": "my-res-pool1"
                            }
                        }]
                    }]
                }
            }],
            "master_azs": ["z1"],
            "worker_azs": ["z1"]
        }
    }
    ```

1. Save the file with a JSON extension. For example, `dev-clusters.json`.

For more example compute profiles, see [Example Compute Profiles](#examples).

###<a id="retrieve-cpi-id"></a> Retrieve the BOSH CPI ID

Use the following procedure to retrieve the BOSH CPI ID for your <%= vars.product_short %> deployment.

1. Locate the credentials that were used to import the Ops Manager .ova or .ovf file into your virtualization system. You configured these credentials when you installed Ops Manager.
    <p class="note"><strong>Note</strong>: If you lose your credentials, you must shut down the Ops Manager VM in the vSphere UI and reset the password. See <a href="https://docs.vmware.com/en/VMware-vSphere/6.5/com.vmware.vsphere.security.doc/GUID-4BDBF79A-6C16-43B0-B0B1-637BF5516112.html">vCenter Password Requirements and Lockout Behavior</a> in the vSphere documentation for more information.</p>

1. From a command line, run the following command to SSH into the Ops Manager VM:

    ```
    ssh ubuntu@OPS-MANAGER-FQDN
    ```
    Where `OPS-MANAGER-FQDN` is the fully qualified domain name (FQDN) of Ops Manager.

1. When prompted, enter the password that you configured during the .ova deployment
into vCenter. For example:
  <pre class="terminal">
  $ ssh ubuntu&#64;my-opsmanager-fqdn.example.com
  Password: ***********
  </pre>

1. Run `bosh cpi-config` to locate the Cloud Provider Interface (CPI) name for your deployment. For example:

    <pre class="terminal">$ bosh cpi-config
    Using environment 'BOSH-DIRECTOR-IP' as client 'ops_manager'
    cpis:
    &#45; migrated_from:
      &#45; name: ""
      name: YOUR-CPI-NAME
    </pre>
    For more information about running BOSH commands in your <%= vars.product_short %> deployment, see [Using BOSH Diagnostic Commands in <%= vars.product_short %>](diagnostic-tools.html).

## <a id='create'></a> Create a Compute Profile

Use the JSON file that contains your compute profile parameters
to make a request to the <%= vars.control_plane %>. The <%= vars.control_plane %> applies the parameters
to your <%= vars.k8s_runtime_abbr %> deployment as a compute profile.

To create the compute profile, run the following command:

```
curl -s -k -X POST "https://TKGI-API:9021/v1/compute-profiles" \
-H "cache-control: no-cache" -H "authorization: Bearer $YOUR-ACCESS-TOKEN" \
-H "Content-Type: application/json" -d "@PATH-TO-YOUR-COMPUTE-PROFILE.json" 
```

Where:

- `TKGI-API` is the FQDN of your <%= vars.control_plane %> endpoint. For example, `api.tkgi.example.com`.
- `YOUR-ACCESS-TOKEN` is your <%= vars.k8s_runtime_abbr %> UAA admin access token specified 
as an environment variable. For information on how to export this token as an environment variable, see [Export <%= vars.control_plane %> Token](login.html#tkgi-api-access).
- `@PATH-TO-YOUR-COMPUTE-PROFILE.json` is the path and filename for the file that contains your compute profile parameters. For example, `@../compute-profiles/dev-clusters.json`.

## <a id='list'></a> List Compute Profiles

You can list compute profiles in your <%= vars.k8s_runtime_abbr %> deployment by making a request to
the <%= vars.control_plane %>.

To list compute profiles, run the following command:

```
curl -s -k  "https://TKGI-API:9021/v1/compute-profiles" \
-H "cache-control: no-cache" -H "authorization: Bearer $YOUR-ACCESS-TOKEN" \
-H "Content-Type: application/json"
```

Where:

- `TKGI-API` is the FQDN of your <%= vars.control_plane %> endpoint. For example, `api.tkgi.example.com`.
- `YOUR-ACCESS-TOKEN` is your <%= vars.k8s_runtime_abbr %> UAA admin access token specified 
as an environment variable. For information on how to export this token as an environment variable, see [Export <%= vars.control_plane %> Token](login.html#tkgi-api-access).

For example:
<pre class="terminal">$ curl -s -k  "https<span>:</span>//api.tkgi.example.com:9021/v1/compute-profiles" \
-H "cache-control: no-cache" -H "authorization: Bearer $YOUR-ACCESS-TOKEN" \
-H "Content-Type: application/json"
[
  {
    "description": "For development clusters",
    "name": "dev",
    "parameters": {
      "azs": [
        {
          "cloud\_properties": {
            "datacenters": [
              {
                "clusters": [
                  {
                    "my-vsphere-cluster": {
                      "drs\_rules": null,
                      "host\_group": null,
                      "resource_pool": "my-res-pool1"
                    }
                  }
                ],
                "name": "my-dc"
              }
            ]
          },
          "cpi": "abc012abc345abc567des",
          "name": "z1"
        }
      ],
      "master\_azs": [
        "z1"
      ],
      "worker\_azs": [
        "z1"
      ]
    },
    "uuid": "618abbcc-4dc5-4080-a24a-56c788b5ed44"
  }
]
</pre>

## <a id='create-cluster'></a> Create a Cluster with a Compute Profile

Define cluster parameters in a JSON file. Include the name of the compute profile
and plan in this file. Then make a request to the <%= vars.control_plane %> to
create the cluster.

To create a cluster with a compute profiles, do the following:

1. Create a new JSON file that describes the cluster that you want to create. Include the
compute profile names in the file. 
For example:

    ```json
    {
      "name": "my-cluster",
      "plan_name": "small",
      "parameters": {
        "kubernetes_master_host": "master.host"
      },
      "compute_profile_name": "dev-clusters",
      "network_profile_name": "my-network-profile"
    }
    ```
    If you are using <%= vars.product_short %> with NSX-T integration, you can optionally specify a network profile. For more information on network profiles, see [Using Network Profiles](network-profiles.html).
1. To create the cluster using the compute profile, run the following command:

    ```
    curl -k -X POST "https://TKGI-API:9021/v1/clusters/" \
    -H "cache-control: no-cache" -H "authorization: Bearer $YOUR-ACCESS=TOKEN" \
    -H "Content-Type: application/json" -d "@PATH-TO-CLUSTER.json"
    ```

    Where:
    - `TKGI-API` is the FQDN of your <%= vars.control_plane %> endpoint. For example, `api.tkgi.example.com`.
    - `YOUR-ACCESS-TOKEN` is your <%= vars.k8s_runtime_abbr %> UAA admin access token specified as an environment variable. For information on how to export this token as an environment variable, see [Export <%= vars.control_plane %> Token](login.html#tkgi-api-access).
    - `@PATH-TO-CLUSTER.json` is the path and filename for the JSON file that you created in [Define a Compute Profile](#define).

    If successful, the cluster creation command outputs something similar to the following:

    <pre class="terminal">
    {
        "name": "k8s1",
        "plan_name": "small",
        "last_action": "CREATE",
        "last_action_state": "in progress",
        "last_action_description": "Creating cluster",
        "uuid": "abcdefg-a123-b456-c789-1011121314",
        "kubernetes_master_ips": ["In Progress"],
        "network_profile_name": "np-tenant-a",
        "compute_profile_name": "",
        "parameters": {
            "kubernetes_master_host": "k8s1.example.com",
            "kubernetes_master_port": 8443,
            "worker_haproxy_ip_addresses": null,
            "kubernetes_worker_instances": 2,
            "authorization_mode": null,
            "nsxt_network_profile": "{\"fip_pool_ids\":[\"abcdefg-b234-c567-d891-hijklmnop\"],\"lb_size\":\"small\",
            \"master_vms_nsgroup_id\":\"0e96f87d-891c-4b32-9757-54051a7f2b91\",\"pod_ip_block_ids\":
            [\"abcdefg-b234-c567-d891-hijklmnop\"],\"pod_routable\":true,\"pod_subnet_prefix\":24,\"t0_router_id\":
            \"zyxwvu-b234-c567-d891-hijklmnop\"}",
            "compute_profile": "{\"azs\":[{\"name\":\"az-1\",\"cpi\":\"abc012abc345abc567des\",\"cloud_properties\":{\"datacenters\":[{\"name\":\"my-dc\",\"clusters\":[{\"cluster1\":{\"resource_pool\":\"tkgi-respool-1\"}}]}]}},{\"name\":\"z2\",\"cpi\":\"abc012abc345abc567des\",\"cloud_properties\":{\"datacenters\":[{\"name\":\"my-dc\",\"clusters\":[{\"cluster2\":{\"resource_pool\":\"tkgi-respool-2\"}}]}]}}],\"worker_azs\":[\"az-2\"],\"master_azs\":[\"az-1\"]}",
            "k8s_customization_parameters": {
                "vsphere_cloud_provider_config_key": null,
                "unset_http_proxy": null,
                "insecure_registries": null
            }
        }
    }
    </pre>

## <a id="resize"></a> Resize a Cluster with a Compute Profile

Currently, you cannot use the <%= vars.control_plane %>
to resize an existing cluster that uses a compute profile. 

To resize an existing cluster, perform the following steps:

1. Delete the cluster by running the `tkgi delete cluster` command. 

1. Recreate the cluster with a compute profile as described in 
[Create a Cluster with a Compute Profile](#create-cluster), 
and specify a larger value for the `kubernetes_worker_instances` parameter 
in your cluster JSON file. 

## <a id="list-clusters"></a> List Clusters with Compute Profile

When you execute the `tkgi clusters` command, the output does not include 
compute profile information for clusters that use compute profiles.

To view compute profile information for all clusters, run the following command:

```
curl -s -k -H "authorization: Bearer $YOUR-ACCESS-TOKEN" "https://TKGI-API:9021/v1/clusters"
```

Where:

- `TKGI-API` is the FQDN of your <%= vars.control_plane %> endpoint. For example, `api.tkgi.example.com`.
- `$YOUR-ACCESS-TOKEN` is your <%= vars.k8s_runtime_abbr %> UAA admin access token specified 
as an environment variable. For information on how to export this token as an environment variable, see [Export <%= vars.control_plane %> Token](login.html#tkgi-api-access).

The output includes compute profile information. 

For example:
<pre class="terminal">$ curl -s -k  "https<span>:</span>//api.tkgi.example.com:9021/v1/clusters" \
-H "cache-control: no-cache" -H "authorization: Bearer $YOUR-ACCESS-TOKEN" \
-H "Content-Type: application/json"
  [
    {
        "name": "cluster-1",
        "plan\_name": "Plan-1",
        "last\_action": "UPDATE",
        "last\_action\_state": "succeeded",
        "last\_action\_description": "Instance update completed",
        "uuid": "123a45bc-de6f-7891-gh23-45hi678912j3",
        "kubernetes\_master\_ips": [
            "10.0.8.6"
        ],
        "network\_profile\_name": "my-net-profile",
        "compute\_profile\_name": "my-compute-profile",
        "parameters": {
            "kubernetes\_master\_host": "cluster-1.virtmerlin.io",
            "kubernetes\_master\_port": 8443,
            "kubernetes\_worker\_instances": 1
        }
    },
    {
        "name": "cluster-2",
        "plan\_name": "Plan-1",
        "last\_action": "UPDATE",
        "last\_action\_state": "succeeded",
        "last\_action\_description": "Instance update completed",
        "uuid": "a9876b54-3c21-9def-87g6-efgh1543219i",
        "kubernetes\_master\_ips": [
            "10.0.8.4"
        ],
        "network\_profile\_name": "my-net-profile-2",
        "compute\_profile\_name": "my-compute-profile-2",
        "parameters": {
            "kubernetes\_master\_host": "cluster-2.virtmerlin.io",
            "kubernetes\_master\_port": 8443,
            "kubernetes\_worker\_instances": 2
        }
    }
]
</pre>

## <a id="delete"></a> Delete Compute Profiles

You can delete compute profiles in your <%= vars.k8s_runtime_abbr %> deployment by making a request to
the <%= vars.control_plane %>.

You cannot delete a compute profile that is applied to an existing cluster. 
First delete any clusters that use the compute profile. 
To delete a cluster using a compute profile, use the `tkgi delete cluster` command. 

To delete a compute profile, run the following command:

```
curl -k -X DELETE  "https://TKGI-API:9021/v1/compute-profiles" \
-H "cache-control: no-cache" -H "authorization: Bearer $YOUR-ACCESS-TOKEN" \
-H "Content-Type: application/json"
```

Where:

- `TKGI-API` is the FQDN of your <%= vars.control_plane %> endpoint. For example, `api.tkgi.example.com`.
- `YOUR-ACCESS-TOKEN` is your <%= vars.k8s_runtime_abbr %> UAA admin access token specified 
as an environment variable. For information on how to export this token as an environment variable, see [Export <%= vars.control_plane %> Token](login.html#tkgi-api-access).

## <a id="examples"></a> Example Compute Profiles

This section includes example compute profiles that define different sets of vSphere resources.

### dev-clusters.json

The following example compute profile for a single cluster uses one AZ and one resource pool:

```json
{
	"name": "dev",
	"description": "For development clusters",
	"parameters": {
		"azs": [{
			"cpi": "abc012abc345abc567des",
			"name": "z1",
			"cloud_properties": {
				"datacenters": [{
					"name": "my-dc",
					"clusters": [{
						"my-vsphere-cluster": {
							"resource_pool": "my-res-pool1"
						    }
					}]
				}]
			}
		}],
       "master_azs": ["z1"],
       "worker_azs": ["z1"]
	}
}
```

### prod-clusters.json

The following example compute profile uses two AZs, with one cluster in the first AZ and three clusters in the second AZ:

```json
{
	"name": "prod",
	"description": "For production clusters",
	"parameters": {
		"azs": [{
                "name": "z1",
				"cpi": "abc012abc345abc567des",
				"cloud_properties": {
					"datacenters": [{
						"name": "my-dc",
						"clusters": [{
							"cluster1": {
								"resource_pool": "rp3"
							}
						}]
					}]
				}
			},
			{
                "name": "z2",
				"cpi": "abc012abc345abc567des",
				"cloud_properties": {
					"datacenters": [{
						"name": "my-dc",
						"clusters": [{
							"cluster2": {
								"resource_pool": "rp1"
							}
						},
							{
							"cluster3": {
								"resource_pool": "rp1"
							}
						},
							{
							"cluster4": {
								"resource_pool": "rp2"
							}
						}]
					}]
				}
			}
	   ],
      "master_azs": ["z1","z2"],
      "worker_azs": ["z1","z2"]
	}
}
```
