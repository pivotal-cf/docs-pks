---
title: PKS Release Notes
owner: PKS
---
## v0.5.0-26 (Dev Release)

**Release Date**: Nov 27, 2017

### Features

* 'Proxy' routing mode has been removed from the PKS tile configuration in Ops Manager. Users can now only set up the tile with external routing mode, requiring an external IP be provided when creating clusters.
* Users of the PKS API can now scale up the number of workers per cluster (note, scaling down is currently not possible). 
* Users can scale a cluster up to 50 workers per cluster in this release. (note, this restriction does not apply to the cluster plan, which is configured in Ops Manager)
* Users of the tile can set a default authorization mode for clusters in either ABAC or RBAC mode. This is a global property.

### Bugs

* There is a bug when users create clusters - the immediate response from the PKS API does not include the plan name or the plan ID. This will be addressed in the next tile release.
* Workers nodes created by PKS have external IPs, which is not the intended function.

### Known Issues

* Operators who deploy the PKS tile on GCP must perform an extra step in this version to set up the cloud config such that the GCP service account used by PKS is specified for each VM. For more information, see  [Step 4: Post-Deployment Steps](installing.html#post-deployment-steps) in <em>Installing and Configuring PKS</em>.
* Users will still have to update the runtime config in BOSH after applying changes, so that cluster creation can occur. For more information, see  [Step 4: Post-Deployment Steps](installing.html#post-deployment-steps) in <em>Installing and Configuring PKS</em>.


## v0.5.0-18 (Dev Release)

**Release Date**: Nov 20, 2017

### Features

* External routing is now an option for PKS. The next release will deprecate the `Proxy` routing mode. Prior to this, users had to provide static IPs for the Kubernetes master and worker HA proxies. Now, choosing external routing mode will allow users to create clusters via an IP not specified in the cloud config. This could be a load balancer given to the user by admins, or self-generated via a load-balancer-as-a-service product in the org. 
* GCP support is also enabled in this version. See the Known Issues section below for details.
* Cluster data in the PKS API will persist after the PKS API is restarted.
* Workloads with persistence can be deployed on clusters created with PKS on vSphere and GCP.
* Users can delete clusters using the PKS API.
* When listing clusters, the PKS API will display clusters while they are deleting.
* The PKS tile configuration allows users to define the default cluster configuration that is deployed with the PKS API.

## Bugs

* The PKS tile configuration for **ETCD VM Type** was located on the wrong page. It has now been relocated alongside other plan configuration fields to the **Plans** section.

## Known Issues

* Operators who deploy the PKS tile on GCP must perform an extra step in this version to set up the cloud config such that the GCP service account used by PKS is specified for each VM. For more information, see  [Step 4: Post-Deployment Steps](installing.html#post-deployment-steps) in <em>Installing and Configuring PKS</em>.
* Users will still have to update the runtime config in BOSH after applying changes, so that cluster creation can occur. For more information, see  [Step 4: Post-Deployment Steps](installing.html#post-deployment-steps) in <em>Installing and Configuring PKS</em>.

## v0.5.0-1 (Dev Release)

**Release Date**: Nov 13, 2017

This is the first release of the Pivotal Container Service (PKS) tile. The tile contains [Cloud Foundry Container Runtime](https://docs-kubo.cfapps.io) (CFCR), an [On-Demand Broker](https://docs.pivotal.io/svc-sdk/odb/), a Service Adapter, and the PKS API. 

This product can be installed independently of the Pivotal Application Service/Elastic Runtime tile and the Cloud Foundry Command Line Interface (cf CLI). The release allows users to interface directly with the PKS API to create Kubernetes clusters on vSphere.

### Features

* The PKS tile is accessible on [Pivotal Network](https://network.pivotal.io) for internal and alpha users.
* Users can use Ops Manager to deploy the tile. See [Installing and Configuring PKS](installing.html) for more information.
* Proxy routing mode enables PKS and `kubo-odb` to be deployed on vSphere with an option for HAProxy routing. 
* Users can create a second Kubernetes cluster on vSphere using the On-Demand Broker. This version includes a workaround to pass the `kubernetes_master_host` and `worker_haproxy_ip_addresses` via the cloud config, to be able to create a cluster without conflicting with IPs that are already used.
* Processes on the broker VM are running as `vcap`. The only process running as `root` is the `bosh-dns-nameserverconfig`, a BOSH job for DNS.
* Cloud Foundry configuration is not required to deploy the On-Demand Broker, as long as startup checks are disabled. PKS will work without a configured Cloud Foundry.
* Users can created, delete, and bind to on-demand service instances without Cloud Foundry configured.
* CFCR 0.8.0 is now available. CFCR was formerly known as Kubo.

### Alpha Features 

<p class="note"><strong>Note</strong>: Because these are alpha features, they may contain bugs.</p>

* Cluster data in the PKS API will persist after restarting PKS.
* Workloads with persistence can be deployed on clusters created with PKS on vSphere.
* Users can delete clusters using the PKS API.
* When listing clusters, the PKS API will display clusters while they are deleting.
* The PKS tile configuration allows users to define the default cluster configuration that is deployed with the PKS API.
* The PKS tile configuration allows users to select a default cluster authorization mode, instead of only deploying clusters with ABAC mode enabled.

## Bug Fixes

* The `worker_node_tag` is no longer required for users to set, and will be inserted into the manifest directly by deployment scripts.

## Known Issues

* The PKS tile is only installable on vSphere. GCP support is coming in the next few releases.
* Ops Manager uses a default runtime config that disables `override_nameserver` for BOSH DNS. You must set this property to `true` in order to enable the CFCR (Kubo) workers to communicate with the CFCR (Kubo) master. To set `override_nameserver` to `true`, perform the following steps:<br><br>
      1. Perform the procedures in [Advanced Troubleshooting with the BOSH CLI](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html) to gather your credential and IP address information for the BOSH Director, SSH into the Ops Manager VM, and log in to the BOSH Director from the Ops Manager VM.  
      1. On the Ops Manager VM, enter the following command to set the `runtime_config` variable:
      <pre class="terminal">$ runtime\_config=$(bosh runtime-config --name ops_manager\_dns\_runtime)</pre>
      1. Use the BOSH CLI v2 to update the runtime config. Enter the following command:
      <pre class="terminal">$ bosh --non-interactive update-runtime-config --name ops\_manager\_dns_runtime \
      <(echo "$runtime\_config" | sed /override\_nameserver/s/false/true/)</pre>

      <p class="note"><strong>Note</strong>: The `override_nameserver` property is reset whenever you click **Apply Changes**, setting the configuration back to `false`.</p>

## Component Versions

The following table lists the component versions for v0.5.0-1 (Dev Release).

  <table>
  <thead>
  <tr>
    <th>Component</th>
    <th>Version</th>
  </tr>
  </thead>
  <tbody>
  <tr>
    <td>CFCR (Kubo)</td><td>0.8.0</td>
  </tr>
  </tbody>
  </table>
