---
title: PKS Release Notes
owner: PKS
---

<strong><%= modified_date %></strong>

This topic contains release notes for Pivotal Container Service (PKS) v1.3.x.

## <a id="v1.3.0"></a>v1.3.0

**Release Date**: January 16, 2019

### <a id="v1.3.0-snapshot"></a>Product Snapshot

<table class="nice">
    <th>Element</th>
    <th>Details</th>
    <tr>
        <td>Version</td>
        <td>v1.3.0</td>
    </tr>
    <tr>
        <td>Release date</td>
        <td>January 16, 2019</td>
    </tr>
    <tr>
        <td>Compatible Ops Manager versions</td>
        <td>v2.3.1+, v2.4.0+</td>
    </tr>
    <tr>
        <td>Stemcell version</td>
        <td>v170.15</td>
    </tr>
    <tr>
        <td>Kubernetes version</td>
        <td>v1.12.4</td>
    </tr>
    <tr>
        <td>On-Demand Broker version</td>
        <td>v0.24</td>
    </tr>
    <tr>
        <td>NSX-T versions <strong>&#42;</strong></td>
        <td>v2.2, v2.3.0.2, v2.3.1</td>
    </tr>
    <tr>
        <td>NCP version</td>
        <td>v2.3.1</td>
    </tr>
    <tr>
        <td>Docker version</td>
        <td>v18.06.1-ce<br><a href="https://github.com/cloudfoundry-incubator/docker-boshrelease/">CFCR</a></td>
    </tr>
</table>

<strong><sup>&#42;</sup></strong> PKS v1.3 supports NSX-T v2.2 and v2.3 with the following caveats:

<ul> 
    <li>To use the network profile features available in PKS v1.3, you must use NSX-T v2.3.</li>
    <li>NSX-T 2.3.0 has a known critical issue: <a href="https://kb.vmware.com/s/article/60293">ESX hosts lose network connectivity rendering the host inaccessible from network (60293)</a>. This issue is patched in NSX-T v2.3.0.2 and fixed in the NSX-T v2.3.1 release.</li>
</ul>

### <a id="v1.3.0-iaas"></a>Feature Support by IaaS

<table>
  <tr>
    <th></th>
    <th>AWS</th>
    <th>Azure</th>
    <th>GCP</th>
    <th>vSphere</th>
    <th>vSphere with NSX-T</th>
  </tr>

  <tr>
    <th>Automatic Kubernetes Cluster API load balancer</th>
    <td></td>
    <td></sup></td>
    <td></td>
    <td></td>
    <td>&check;</td>
  </tr>
  <tr>
    <th>HTTP proxy</th>
    <td></td>
    <td></sup></td>
    <td></td>
    <td>&check;</td>
    <td>&check;</td>
  </tr>
  <tr>
    <th>Multi-AZ storage</th>
    <td></td>
    <td></sup></td>
    <td></td>
    <td>&check;</td>
    <td>&check;</td>
  </tr>
  <tr>
    <th>Per-namespace subnets</th>
    <td></td>
    <td></sup></td>
    <td></td>
    <td></td>
    <td>&check;</td>
  </tr>
  <tr>
    <th>Service <code>type:LoadBalancer</code></th>
    <td>&check;<sup>&#42;</sup></td>
    <td>&check;</sup></td>
    <td>&check;</td>
    <td></td>
    <td>&check;</td>
  </tr>
</table>

<sup>&#42;</sup> For more information about configuring Service `type:LoadBalancer` on AWS, see the [Access Workloads Using an Internal AWS Load Balancer](deploy-workloads.html#internal-lb) section of _Deploying and Accessing Basic Workloads_.

### <a id="v1.3.0-upgrade"></a>Upgrade Path

The supported upgrade paths to PKS v1.3.0 are from PKS v1.2.5 and later.

For more information, see [Upgrading PKS](upgrade-pks.html) and [Upgrading PKS with NSX-T](upgrade-pks-nsxt.html).

<p class="note"><strong>Note</strong>: Upgrading from PKS v1.2.5+ to PKS v1.3.x causes all certificates to be automatically regenerated. The old certificate authority is still trusted, and has a validity of one year. But the new certificates are signed with a new certificate authority, which is valid for four years.</p>

### <a id="v1.3.0-whats-new"></a>What's New

PKS v1.3.0 adds the following:

- Support for PKS on Azure. For more information, see [Azure](azure-index.html).
- BOSH Backup and Restore (BBR) for single-master clusters. For more information, see [Backing up the Single Master Cluster](bbr-backup-cluster.html) and [Restoring the Single Master Cluster](bbr-restore-cluster.html).
- Routable pods on NSX-T. For more information, see [Routable Pod Networks](network-profiles-define.html#routable-pods) in <em>Defining Network Profiles</em>.
- Large size NSX-T load balancers with Bare Metal NSX-T edge nodes. For more information, see [Hardware Requirements for PKS on vSphere with NSX-T](vsphere-nsxt-rpd-mpd.html#pks-edge-cluster).
- HTTP proxy for NSX-T components. For more information, see [Using Proxies with PKS on NSX-T](proxies.html).
- Ability to specify the size of the Pods IP Block subnet using a network profile. For more information, see [Pod Subnet Prefix](./network-profiles-define.html#pod-prefix) in <em>Defining Network Profiles</em>.
- Support for bootstrap security groups, custom floating IPs, and edge router selection using network profiles. For more information, see [Bootstrap Security Group](network-profiles-define.html#ns-groups), [Custom Floating IP Pool](network-profiles-define.html#floating-ip), and [Edge Router Selection](network-profiles-define.html#multi-t0) in <em>Defining Network Profiles</em>.
- Support for sink resources in air-gapped environments.
- Support for creating sink resources with the PKS Command Line Interface (PKS CLI). For more information, see [Creating Sink Resources](create-sinks.html).
- Sink resources include both pod logs as well as events from the Kubernetes API. These events are combined in a shared format that provides operators with a robust set of filtering and monitoring options. For more information, see [Monitoring PKS with Sinks](monitor-sinks.html).
- Support for multiple NSX-T Tier-0 (T0) logical routers for use with PKS multi-tenant environments. For more information, see [Configuring Multiple Tier-0 Routers for Tenant Isolation](nsxt-multi-t0.html).
- Support for multiple PKS foundations on the same NSX-T. For more information, see [Implementing a Multi-Foundation PKS Deployment](nsxt-multi-pks.html). 
- Smoke tests errand that uses the PKS CLI to create a Kubernetes cluster and then delete it. If the creation or deletion fails, the errand fails and the installation of the PKS tile is aborted. For more information, see the <em>Errands</em> section of the <em>Installing PKS</em> topic for your IaaS, such as [Installing PKS on vSphere](installing-pks-vsphere.html#errands).
- Support for scaling down the number of worker nodes. For more information, see [Scaling Existing Clusters](scale-clusters.html).
- Support for defining the CIDR range for Kubernetes pods and services on Flannel networks. For more information, see the <em>Networking</em> section of the <em>Installing PKS</em> topic for your IaaS, such as [Installing PKS on vSphere](installing-pks-vsphere.html#networking).
- Kubernetes v1.12.4.  
- **Bug Fix**: The **No proxy** property for vSphere now accepts wildcard domains like
`*.example.com` and `example.com`. See [Networking](./installing-pks-vsphere.html#networking) in
_Installing PKS on vSphere_ for more information.
- **Bug Fix**: The issue with NSX-T where special characters in username and password doesn't work is resolved.
- **Security Fix**: [CVE 2018-18264](https://pivotal.io/security/cve-2018-18264): This CVE allows unauthenticated secret access to the Kubernetes Dashboard.
- **Security Fix**: [CVE-2018-15759](https://pivotal.io/security/cve-2018-15759): This CVE contains an insecure method of verifying credentials. A remote unauthenticated malicious user may make many requests to the service broker with a series of different credentials, allowing them to infer valid credentials and gain access to perform broker operations.

### <a id="v1.3.0-known-issues"></a>Breaking Changes and Known Issues

<p class="note breaking"><strong>Breaking Change:</strong> Heapster is deprecated in PKS v1.3, and
Kubernetes has retired Heapster. For more information, see the
<a href="https://github.com/kubernetes-retired/heapster">kubernetes-retired/heapster</a>
repository in GitHub.</p>

PKS v1.3.0 has the following known issues:

####<a id="flannel"></a> PKS Flannel Network Gets Out of Sync with Docker Bridge Network (cni0)

When VMs have been powered down for multiple days, turning them back on and issuing a `bosh recreate` to recreate the VMs causes the pods to get stuck in a `ContainerCreating` state.

**Workaround**: See [PKS Flannel network gets out of sync with docker bridge network (cni0)](https://community.pivotal.io/s/article/PKS-Flannel-network-gets-out-of-sync-with-docker-bridge-network-cni0) in the Pivotal Knowledge Base.

