---
title: PKS Release Notes
owner: PKS
---

<strong><%= modified_date %></strong>

This topic contains release notes for Pivotal Container Service (PKS) v1.1.x.

## <a id="v1.1.6"></a>v1.1.6

**Release Date**: September 24, 2018

### <a id="v1.1.6-snapshot"></a>Product Snapshot

<table class="nice">
    <th>Element</th>
    <th>Details</th>
    <tr>
        <td>Version</td>
        <td>v1.1.6</td>
    </tr>
    <tr>
        <td>Release date</td>
        <td>September 24, 2018</td>
    </tr>
    <tr>
        <td>Compatible Ops Manager versions</td>
        <td>v2.1.x, v2.2.x</td>
    </tr>
    <tr>
        <td>Stemcell version</td>
        <td>3586.42</td>
    </tr>
    <tr>
        <td>Kubernetes version</td>
        <td>v1.10.7
    </tr>
    <tr>
        <td>NSX-T version</td>
        <td>v2.1, v2.2</td>
    </tr>
    <tr>
        <td>NCP version</td>
        <td>v2.2.1</td>
    </tr>
</table>

### <a id="v1.1.6-what's-new"></a>What's New

- Updates stemcell to v3586.42.
- Updates Kubernetes to v1.10.7.
- The default for the Worker Persistent Disk Type has been updated to 50GB.
- The default for the Master/ETCD and Worker VM Type has been updated to 32GB disk.

### <a id="v1.1.6-known-issues"></a>Known Issues
- The default for the Master/ETCD VM Type on Plan 2 should be updated to have a minimum disk size of 32GB.

## <a id="v1.1.5"></a>v1.1.5

**Release Date**: August 31, 2018

### <a id="v1.1.5-snapshot"></a>Product Snapshot

<table class="nice">
    <th>Element</th>
    <th>Details</th>
    <tr>
        <td>Version</td>
        <td>v1.1.5</td>
    </tr>
    <tr>
        <td>Release date</td>
        <td>August 31, 2018</td>
    </tr>
    <tr>
        <td>Compatible Ops Manager versions</td>
        <td>v2.1.x, v2.2.x</td>
    </tr>
    <tr>
        <td>Stemcell version</td>
        <td>3586.36</td>
    </tr>
    <tr>
        <td>Kubernetes version</td>
        <td>v1.10.5
    </tr>
    <tr>
        <td>NSX-T version</td>
        <td>v2.1, v2.2</td>
    </tr>
    <tr>
        <td>NCP version</td>
        <td>v2.2.1</td>
    </tr>
</table>

### <a id="v1.1.5-what's-new"></a>What's New

- Updates stemcell to 3586.36.
- Adds support for NSX-T v2.2.
- Updates NCP to v2.2.1.
- [NSX-T Architectural Changes](#arch-changes)

### <a id="v1.1.5-known-issues"></a>Known Issues

You cannot enter whitespace into any of the fields in the PKS tile, including leading and trailing spaces and spaces between characters. Using a space in any field causes the PKS deployment to fail.

The following known issues apply to PKS deployments on vSphere with NSX-T:
<p class="note"><strong>Note</strong>: The issues listed below pertain to NSX-T v2.2 and NCP v2.2.1. NSX-T v2.3 and NCP v2.3 include fixes for these issues. PKS support for these versions is under development for a future release.</p>

- Updating load balancer rules fails from TLS ingress to non-TLS ingress with NCP restart.
- Stale pool found when deleting an ingress rule which is updated from non-TLS to TLS.
- Deletion of HTTPS VS pool fails after updating NCP.
- NCP crashes on restart if the load balancer has max virtual servers.
- TLS ingress certificate is not removed after deleting all related TLS ingress objects.
- SNI certificate is not updated after changing non-TLS ingress to TLS ingress with NCP restart.
- NCP error annotations are not found when updating the LBIPPool from a valid to nonexistent IPPool.
- NSX cleanup operation does not release the external IP or delete SNAT rules on the T0 router.

The following known issue applies to PKS deployments on GCP:

* If you use stemcell v3586.18 or later
in the 3586 line of Linux stemcells
when deploying PKS on GCP, you may see the following:

  * The output of the `bosh vms` command
  shows an error message that includes `unresponsive agent`.
  * Your PKS-provisioned Kubernetes cluster does not respond to any PKS CLI commands,
  such as `pks get-credentials` or `pks delete-cluster`.

    Until this issue is resolved,
    use stemcell v3586.16 when deploying PKS on GCP.

### <a id="arch-changes"></a>NSX-T Architectural Changes

<p class="note"><strong>Note</strong>: The changes in this section apply to PKS deployments on vSphere with NSX-T.</p>

PKS v1.1.5 includes architectural changes related to its integration with NSX-T
and NCP. PKS uses NCP to integrate with NSX-T. For more information about NCP,
see [Overview of NSX-T Container Plug-in](https://docs.vmware.com/en/VMware-NSX-T/2.0/com.vmware.nsxt.ncp_kubernetes.doc/GUID-52A92986-0FDF-43A5-A7BB-C037889F7559.html) in the VMware documentation.

#### <a id="nsxt-node"></a>NSX-T Node Agent and Kube Proxy

In PKS v1.1.4 and earlier, the NSX-T Node Agent and NSX-T Kube Proxy run as a
daemon set on each worker node. In PKS v1.1.5, both the NSX-T Node Agent and
the Kube Proxy run as BOSH-managed processes on each worker node.

#### <a id="ncp"></a>NSX-T Container Plugin (NCP)

<p class="note"><strong>Note</strong>: You do not need to install or configure NCP. NCP is automatically installed and configured when you deploy PKS in an NSX-T environment.</p>

In PKS v1.1.4 and earlier, NCP runs as a Kubernetes pod on a single worker
node. With PKS v1.1.5, NCP runs as a BOSH-managed process on the Kubernetes
master node.

In PKS v1.1.5, if you deploy a multi-master cluster, the NCP process
runs on all master nodes but is active on only a single master. If the
NCP process on an active master is unresponsive, BOSH activates another NCP
process.

#### <a id="logs"></a>PKS Logs for NSX-T and NCP

In PKS v1.1.4 and earlier, you access NSX-T and NCP logs using `kubectl` commands. In PKS v1.1.5, NSX-T and NCP are BOSH-managed processes, and you access the logs for these components using BOSH.

BOSH jobs related to NSX-T integration with NCP as a BOSH process:

<table class="nice">
  <tr>
    <th>Location</th>
    <th>BOSH Jobs</th>
  </tr>
  <tr>
    <td rowspan="3">Master Node</td>
    <td><code>/var/vcap/sys/log/ncp</code></td>
  </tr>
  <tr>
    <td><code>/var/vcap/sys/log/pks-nsx-t-prepare-master-vm</code></td>
  </tr>
  <tr>
    <td><code>/var/vcap/sys/log/pks-nsx-t-ncp</code></td>
  </tr>
  <tr>
    <td rowspan="4">Worker Nodes</td>
    <td><code>/var/vcap/sys/log/nsx-kube-proxy</code></td>
  </tr>
  <tr>
    <td><code>/var/vcap/sys/log/openvswitch</code></td>
  </tr>
  <tr>
    <td><code>/var/vcap/sys/log/nsx-cni</code></td>
  </tr>
  <tr>
    <td><code>/var/vcap/sys/log/nsx-node-agent</code></td>
  </tr>
</table>

Run the BOSH command `bosh â€“d MY-DEPLOYMENT logs` to collect these logs, replacing
`MY-DEPLOYMENT` with the name of your PKS deployment.
For more information, see [Using Logs](https://bosh.io/docs/job-logs/) in the BOSH
documentation.

When you upgrade to PKS v1.1.5, the existing logs for NSX-T and NCP are
deleted. Before you upgrade, you may want to back these logs up. For example,
you may need to analyze these logs if you experience problems with your PKS
deployment before upgrading, or problems related to a failed upgrade.

## <a id="v1.1.4"></a>v1.1.4

**Release Date**: August 8, 2018

### <a id="v1.1.4-snapshot"></a>Product Snapshot

<table class="nice">
    <th>Element</th>
    <th>Details</th>
    <tr>
        <td>Version</td>
        <td>v1.1.4</td>
    </tr>
    <tr>
        <td>Release date</td>
        <td>August 8, 2018</td>
    </tr>
    <tr>
        <td>Compatible Ops Manager versions</td>
        <td>v2.1.x, v2.2.x</td>
    </tr>
    <tr>
        <td>Stemcell version</td>
        <td>3586.27</td>
    </tr>
    <tr>
        <td>Kubernetes version</td>
        <td>v1.10.5
    </tr>
    <tr>
        <td>NSX-T version</td>
        <td>v2.1</td>
    </tr>
    <tr>
        <td>NCP version</td>
        <td>v2.2</td>
    </tr>
</table>

### <a id="v1.1.4-what's-new"></a>What's New

- Updates stemcell to 3586.27.
- Updates Kubernetes to v1.10.5.
- Includes security enhancements.

### <a id="v1.1.4-known-issues"></a>Known Issues

* If you use stemcell v3586.18 or later
in the 3586 line of Linux stemcells
when deploying PKS on GCP, you may see the following:

  * The output of the `bosh vms` command
  shows an error message that includes `unresponsive agent`.
  * Your PKS-provisioned Kubernetes cluster does not respond to any PKS CLI commands,
  such as `pks get-credentials` or `pks delete-cluster`.

    Until this issue is resolved,
    use stemcell v3586.16 when deploying PKS on GCP.

## <a id="v1.1.3"></a>v1.1.3

**Release Date**: July 30, 2018

### <a id="v1.1.3-snapshot"></a>Product Snapshot

<table class="nice">
    <th>Element</th>
    <th>Details</th>
    <tr>
        <td>Version</td>
        <td>v1.1.3</td>
    </tr>
    <tr>
        <td>Release date</td>
        <td>July 30, 2018</td>
    </tr>
    <tr>
        <td>Compatible Ops Manager versions</td>
        <td>v2.1.x, v2.2.x</td>
    </tr>
    <tr>
        <td>Stemcell version</td>
        <td>3586.26</td>
    </tr>
    <tr>
        <td>Kubernetes version</td>
        <td>v1.10.4
    </tr>
</table>

### <a id="v1.1.3-what's-new"></a>What's New

* Updates stemcell to 3586.26.
* Telemetry information is now sent less frequently.

### <a id="v1.1.3-known-issues"></a>Known Issues

* If you use stemcell v3586.18 or later
in the 3586 line of Linux stemcells
when deploying PKS on GCP, you may see the following:

  * The output of the `bosh vms` command
  shows an error message that includes `unresponsive agent`.
  * Your PKS-provisioned Kubernetes cluster does not respond to any PKS CLI commands,
  such as `pks get-credentials` or `pks delete-cluster`.

    Until this issue is resolved,
    use stemcell v3586.16 when deploying PKS on GCP.

## <a id="v1.1.2"></a>v1.1.2

**Release Date**: July 17, 2018

### <a id="v1.1.2-snapshot"></a>Product Snapshot

<table class="nice">
    <th>Element</th>
    <th>Details</th>
    <tr>
        <td>Version</td>
        <td>v1.1.2</td>
    </tr>
    <tr>
        <td>Release date</td>
        <td>July 17, 2018</td>
    </tr>
    <tr>
        <td>Compatible Ops Manager versions</td>
        <td>v2.1.x, v2.2.x</td>
    </tr>
    <tr>
        <td>Stemcell version</td>
        <td>3586.24</td>
    </tr>
    <tr>
        <td>Kubernetes version</td>
        <td>v1.10.4
    </tr>
</table>

### <a id="v1.1.2-security-fixes"></a>Security Fixes

This release includes the following security fix:

* High [CVE-2018-11047: UAA accepts refresh token as access token on admin endpoints](https://www.cloudfoundry.org/blog/cve-2018-11047/)

### <a id="v1.1.2-known-issues"></a>Known Issues

* If you use stemcell v3586.18 or later
in the 3586 line of Linux stemcells
when deploying PKS on GCP, you may see the following:

  * The output of the `bosh vms` command
  shows an error message that includes `unresponsive agent`.
  * Your PKS-provisioned Kubernetes cluster does not respond to any PKS CLI commands,
  such as `pks get-credentials` or `pks delete-cluster`.

    Until this issue is resolved,
    use stemcell v3586.16 when deploying PKS on GCP.

## <a id="v1.1.1"></a>v1.1.1

**Release Date**: July 16, 2018

### <a id="v1.1.2-snapshot"></a>Product Snapshot

<table class="nice">
    <th>Element</th>
    <th>Details</th>
    <tr>
        <td>Version</td>
        <td>v1.1.1</td>
    </tr>
    <tr>
        <td>Release date</td>
        <td>July 16, 2018</td>
    </tr>
    <tr>
        <td>Compatible Ops Manager versions</td>
        <td>v2.1.x, v2.2.x</td>
    </tr>
    <tr>
        <td>Stemcell version</td>
        <td>3586.24</td>
    </tr>
    <tr>
        <td>Kubernetes version</td>
        <td>v1.10.4
    </tr>
</table>

<p class="note"><strong>Note:</strong> PKS v1.1.1 and later supports Ops Manager v2.1 and v2.2. Pivotal recommends using Ops Manager v2.2 to deploy PKS. For added security in Ops Manager v2.2, disable the <b>Allow Legacy Agents</b> option in the <b>Director Config</b> pane of the BOSH Director tile. For more information, see the Ops Manager configuration topic for your cloud provider. For example, <a href="vsphere-om-config.html#dir-config">Configuring Ops Manager on vSphere</a>.</p>

### <a id="v1.1.1-what's-new"></a>What's New

- UAA and security enhancements
- NSX-T patches
- Telemetry patch
- Kubernetes 1.10.4

### <a id="v1.1.1-bug-fixes"></a>Bug Fixes

PKS v1.1.1 now supports Ops Manager v2.1.7 and later. However, Pivotal recommends using Ops Manager v2.2 to deploy PKS.

### <a id="v1.1.1-upgrade"></a>Upgrade Procedure

To upgrade to PKS v1.1.1, you must upgrade from PKS v1.0.2 or later.

To upgrade to PKS v1.1.1, follow the procedures in [Upgrading PKS](upgrade-pks.html). Pivotal recommends using Ops Manager v2.2 to deploy PKS.

For added security in Ops Manager v2.2, disable the <b>Allow Legacy Agents</b> option in the <b>Director Config</b> pane of the BOSH Director tile. For more information, see the Ops Manager configuration topic for your cloud provider. For example, <a href="vsphere-om-config.html#dir-config">Configuring Ops Manager on vSphere</a>.

### <a id="v1.1.1-known-issues"></a>Known Issues

* If you use stemcell v3586.18 or later
in the 3586 line of Linux stemcells
when deploying PKS on GCP, you may see the following:

  * The output of the `bosh vms` command
  shows an error message that includes `unresponsive agent`.
  * Your PKS-provisioned Kubernetes cluster does not respond to any PKS CLI commands,
  such as `pks get-credentials` or `pks delete-cluster`.

    Until this issue is resolved,
    use stemcell v3586.16 when deploying PKS on GCP.

## <a id="v1.1.0"></a>v1.1.0

<p class="note warning"><strong>WARNING:</strong> PKS v1.1.0 is no longer available for download from Pivotal Network.</p>

**Release Date**: June 28, 2018

### <a id="v1.1.0-upgrade"></a>Upgrade Procedure

<p class="note"><strong>Note</strong>:
The only supported upgrade path for PKS v1.1.0 is from PKS v1.0.2 and later. Do not upgrade directly to PKS v1.1.0 from v1.0.0. Instead, first upgrade PKS v1.0.0 to v1.0.2; then upgrade PKS v1.0.2 to v1.1.0. Alternatively, do a clean install of PKS v1.1.0.
</p>

To upgrade to PKS v1.1.0, follow the procedures in [Upgrading PKS](upgrade-pks.html).

### <a id="v1.1.0-features"></a>Features

This section describes new features introduced in PKS v1.1.0.

#### General Features

* Adds support for Kubernetes 1.10.3.
* Adds support for backing up and restoring PKS using BOSH Backup and Restore (BBR). For more information, see [Backing Up and Restoring PKS](backup-and-restore.html).
* Adds support for granting PKS control plane access to clients and external LDAP groups. For more information, see the [Grant Cluster Access](manage-users.html#cluster-access) section of _Manage Users in UAA_.
* Adds support for allowing workers to be deployed across Availability Zones (AZs).
* Adds support for network automation and node network isolation.
* Adds support for NFS by enabling rpcbind on worker nodes.
* Adds support for kube-controller-manager to issue certificates.
* Adds support for configuring HTTP/HTTPS proxy to be used by the Kubernetes control plane.
* Adds support for configuring the SecurityContextDeny admission controller. For more information, see [Using Admission Controllers](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/) in the Kubernetes documentation.
* Enables the MutatingAdmissionWebhook admission controller. For more information, see [Using Admission Controllers](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/) in the Kubernetes documentation.
* Enables audit logging for the API server.
* Creates logs for delete-all-cluster errands in the /var/vcap/sys/log/delete-all-clusters folder on the PKS control plane VM.
* Adds BOSH instance IDs to worker node labels.
* Hardens security by removing the ABAC authorization option for clusters.
* Hardens security by using service account IDs instead of service account keys for GCP deployments.
* Hardens security for Kubernetes system components. For example, kube-dns now uses its own configuration instead of the kubelet configuration.

#### vSphere Features

* Adds support for NO-NAT deployment topologies for PKS installations on NSX-T. For more information, see [Deployment Topologies](nsxt-topologies.html).
* Adds support for PKS integration with [VMware Wavefront](https://www.wavefront.com) to capture metrics for clusters and pods. For more information, see the (Optional) Logging section of _Installing PKS_ for your IaaS. For example, see [Installing PKS on vSphere](installing-pks-vsphere.html#syslog).
* Adds support for node network access using HTTP proxy for vSphere deployments. For more information, see the [Networking](installing-pks-vsphere.html#networking) section of _Installing PKS on vSphere_.
* Adds support for PKS integration with [VMware vRealize Log Insight (vRLI)](https://www.vmware.com/products/vrealize-log-insight.html) for tagged logging of the control plane, clusters, and pods. For more information, see the (Optional) Monitoring section of _Installing PKS_ for your IaaS. For example, see [Installing PKS on vSphere](installing-pks-vsphere.html#monitoring).

* Adds support for integration with [VMware Analytics Cloud (VAC)](https://codepen.io/didkobravo/project/live/AYdRpX) to capture telemetry information.
* Hardens security by removing VM change permissions from worker nodes for vSphere deployments.
* Hardens security by removing vCenter user credentials from worker nodes for vSphere deployments.
* Adds support for [Harbor Registry]( https://vmware.github.io/harbor/) integration enhancements: updated Harbor tile, ability to use NFS and Google Buckets as an image store, and HTTP/HTTPS proxy servers for Clair.

### <a id="v1.1.0-features"></a>Bug Fixes

* Prevents unnecessary route creation in the kube-controller-manager.
* Retains the original source IP when using Flannel.
* Disables the read-only port in the kubelet configuration.
* Disables cAdvisor in the kubelet configuration.
* For added security, the Kubernetes API server no longer tries to fix malformed requests.
* The Kubernetes API server now cleans up terminated pods more often to avoid running out of disk space.
* The Kubernetes API server now unmounts volumes of terminated pods for security reasons.
* Operators no longer have to manually delete NSX-T objects created during the life of the product. In PKS v1.1, running the `pks delete-cluster` command deletes all NSX objects.

### <a id="v1.1.0-beta"></a>Beta Components

* Adds support for deploying multiple Kubernetes master nodes across AZs. For information about configuring multiple masters, see the Plans section of _Installing PKS_ for your IaaS. For example, see [Installing PKS on vSphere](installing-pks-vsphere.html#plans).

  <%= partial 'beta-component' %>

<p class="note warning"><strong>WARNING</strong>: You cannot change the number of master nodes for existing clusters. To use the multi-master feature, you must create a new plan that uses multiple master/etcd nodes and deploy a new cluster. If you are already using all three plan configurations in the PKS tile, you must delete a plan and all clusters you deployed using that plan before you can deploy a multi-master cluster.</p>

### <a id="v1.1.0-versions"></a>Component Versions

PKS v1.1.0 includes or supports the following component versions:

<p class="note warning"><strong>WARNING</strong>: PKS v1.1.0 does not support Ops Manager v2.1.7 and later.</p>

<table border="1" class="nice">
<tbody>
  <tr>
    <th>Product Component</th>
    <th>Version Supported</th>
    <th>Notes</th>
   </tr>
   <tr>
     <td>Pivotal Cloud Foundry Operations Manager (Ops Manager)</td>
     <td>2.1.0-2.1.6</td>
   <td>Separate download available from Pivotal Network</td>
   </tr>
   <tr>
   <td>Stemcell</td>
   <td>3586.24</td>
   <td></td>
   </tr>
   <tr>
   <td>Kubernetes</td>
   <td>1.10.3</td>
   <td>Packaged in the PKS Tile (CFCR)</td>
   </tr>
   <tr>
   <td>CFCR (Kubo)</td>
   <td>0.17</td>
   <td>Packaged in the PKS Tile</td>
   </tr>
   <tr>
   <td>Golang</td>
   <td>1.9.7</td>
   <td>Packaged in the PKS Tile</td>
   </tr>
   <tr>
   <td>NCP</td>
   <td>2.2</td>
   <td>Packaged in the PKS Tile</td>
   </tr>
   <tr>
   <td>Kubernetes CLI</td>
   <td>1.10.3</td>
   <td>Separate download available from the PKS section of Pivotal Network</td>
   </tr>
   <tr>
   <td>PKS CLI</td>
   <td>1.1</td>
   <td>Separate download available from the PKS section of Pivotal Network</td>
   </tr>
   <tr>
   <td>VMware vSphere</td>
   <td>6.5 U2 and 6.5 U1. Editions:
     <ul>
       <li>vSphere Enterprise Plus Edition</li>
       <li>vSphere with Operations Management Enterprise Plus</li>
     </ul>
   </td>
   <td>vSphere versions supported for Pivotal Container Service (PKS)</td>
   </tr>
   <td>VMware NSX-T</td>
   <td>2.1 - Advanced Edition</td>
   <td>NSX-T versions supported for Pivotal Container Service (PKS)</td>
   </tr>
   <tr>
   <td>VMware Harbor Registry</td>
   <td>1.5.0</td>
   <td>Separate download available from Pivotal Network</td>
   </tr>
   <tr>
   <td>VMware vRealize Log Insight (for vSphere deployments)</td>
   <td>4.6</td>
   <td>Separate download available from Pivotal Network</td>
   </tr>
   </tbody>
   <tfoot>
   <tr>
    <td colspan="3"><em>* Components marked with an asterisk have been patched to resolve security vulnerabilities or fix component behavior.</em></td>
   </tr>
  </tfoot>
</table>

### <a id="known-issues"></a>Known Issues

This section includes known issues with PKS v1.1.0 and corresponding workarounds.

* PKS v1.1.0 does not support Ops Manager v2.1.7 and later.
For more information, see [Error: Duplicate Variable Name](troubleshoot-issues.html#duplicate-name) in the _Troubleshooting_ topic.
* If you use PKS CLI v1.0.x with PKS tile v1.1.x, you must log in every 600
seconds to manually refresh the CLI token.
Pivotal recommends upgrading to PKS CLI v1.1.x to solve this issue.
* If you upgrade PKS from v1.0.x to v1.1, you must enable the **Upgrade All Clusters** errand in the PKS tile configuration.
This ensures existing clusters can perform resize or delete actions after
the upgrade.
* If you use stemcell v3586.18 or later
in the 3586 line of Linux stemcells
when deploying PKS on GCP, you may see the following:

  * The output of the `bosh vms` command
  shows an error message that includes `unresponsive agent`.
  * Your PKS-provisioned Kubernetes cluster does not respond to any PKS CLI commands,
  such as `pks get-credentials` or `pks delete-cluster`.

    Until this issue is resolved,
    use stemcell v3586.16 when deploying PKS on GCP.

#### <a id="compromised-cluster"></a>Cluster Security Recommendations

To reduce the risk of compromised clusters in your PKS deployment, the following policies are recommended:

* Ensure that only trusted operators and systems have access to clusters.
* Ensure that only trusted images are deployed to clusters.
* Maintain trusted images to consistently include current security fixes.
* Do not expose network ports to untrusted networks unless strictly required.

#### <a id="target-lb"></a>Reconfigure GCP Load Balancers After Master VM Recreation

If Kubernetes master node VMs are recreated for any reason, you must reconfigure your cluster load balancers to point to the new master VMs.
For example, after a stemcell upgrade, BOSH recreates the VMs in your deployment.

To reconfigure your GCP cluster load balancer to use the new master VM, follow the procedure in the [Reconfiguring a GCP Load Balancer](gcp-cluster-load-balancer.html#reconfigure) section of <em>Configuring a GCP Load Balancer for PKS Clusters</em>.

#### <a id="abac-clusters"></a>Existing ABAC Clusters

Attribute-based access control (ABAC) is no longer supported in v1.1.
Delete any ABAC clusters before upgrading to v1.1.

#### <a id="default-vm-type"></a>New Default VM Type

In the **Resource Config** pane, the default **VM Type** is now **large**.
This is to ensure that PKS control plane VM has sufficient resources.

If the VMs in your PKS installation use the default VM type, your VMs will use the new **large** VM type after upgrading to PKS v1.1.0.

If the VMs in your PKS installation use a custom VM type, your configuration remains the same after upgrading to PKS v1.1.0.
