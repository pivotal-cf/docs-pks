---
title: Create Clusters in the Management Console
owner: TKGI
---

You can deploy Kubernetes clusters to <%= vars.product_short %> directly from  <%= vars.product_short %> Management Console on vSphere.

When you deploy Kubernetes clusters from the management console, you select the following pre-existing resources to configure your cluster:

- A plan from the list of plans that were defined when the management console was deployed.
- An optional network profile. Network profiles allow cluster administrators and cluster managers to customize the networking for different types of Kubernetes cluster. For information about how to create network profiles in the management console, see [Working with Network Profiles](console-network-profile.html).
- An optional Kubernetes profile. Kubernetes profiles enable cluster administrators and cluster managers to customize Kubernetes component settings for any clusters that they provision. You create Kubernetes profiles outside of the management console, by using the <%= vars.k8s_runtime_abbr %> CLI to define the Kubernetes profile in your <%= vars.product_short %> instance.

## <a id='create-clusters'></a> Create Clusters

1. Go to the **TKG Integrated Edition** view of the management console.
1. Select the **Clusters** tab and click **Create Cluster**.
    ![Create cluster](images/console/create-cluster.png)
    [View a larger version of this image](images/console/create-cluster.png)
1. Use the **Plan** drop-down menu to select one of the plans that were configured during the deployment of <%= vars.product_short %> Management Console.

    The plan defines the set of resources that the Kubernetes cluster will use. A summary of the selected plan appears as you hover over each option.
    ![Select plan for cluster](images/console/select-plan.png)
1. Enter a name and a host name for the cluster, and specify the number of worker nodes to create.

    ![Cluster name and hostname](images/console/configure-cluster.png)
    <p class="note"><strong>Note</strong>: Use only lowercase characters when naming your cluster 
    if you manage your clusters with Tanzu Mission Control (TMC). Clusters with names that include an uppercase character cannot be attached to TMC.
    </p>
1. Use the **Network Profile** and **Compute Profile** drop-down menus to select existing network and compute profiles for the cluster to use.

    ![Network profile](images/console/select-network-profile.png)

     If you have not created any network or compute profiles, the management console uses the default profiles. In this case, <%= vars.product_short %> Management Console configures networking and compute for you, based on the plan that you selected.
1. Optionally use the Kubernetes Profile drop-down menu to select an existing Kubernetes profile for the cluster to use.

    ![Kubernetes profile](images/console/select-k8s-profiles.png)

     If you have not created any Kubernetes profiles, the management console uses the default Kubernetes profile. In this case, <%= vars.product_short %> Management Console configures the cluster for you, based on the plan that you selected.

1. Click **Create** to deploy your cluster.

    You can follow the progress of the deployment of your cluster in the **Clusters** tab.
    ![All clusters](images/console/summary-clusters.png)

## <a id='update-clusters'></a> Update Cluster Configuration  

After you have deployed clusters, you can modify their configuration when they are in the Running state.

1. Select a cluster in the **Clusters** tab and click **Update**.
    ![Update cluster](images/console/update-cluster.png)
1. Use the drop-down menus to optionally change the network, compute, or Kubernetes profiles for the cluster.
1. Optionally click **Modify Worker Nodes** to update the number of worker nodes.
    ![Custer advanced settings](images/console/update-cluster-settings.png)
1. Optionally expand **Advanced Settings** to update the settings for node drain and the pod shutdown grace period.
    ![Custer advanced settings](images/console/update-cluster-adv-settings.png)
    
## <a id='upgrade-clusters'></a> Upgrade Clusters to a New Version of Kubernetes

If you make a new version of Kubernetes available by upgrading <%= vars.product_short %> Management Console, you can upgrade your existing clusters in the management console.

1. Go to the **TKG Integrated Edition** view of the management console.
1. Select the **Clusters** tab.
1. Select one or more clusters and click **Upgrade**.

    Clusters must be in the running state for upgrade to be possible.

    ![Create cluster](images/console/upgrade-cluster.png)
    [View a larger version of this image](images/console/upgrade-cluster.png)
1. Click **Upgrade** to confirm.

    ![Create cluster](images/console/upgrade-cluster-confirm.png)
    [View a larger version of this image](images/console/upgrade-cluster-confirm.png)
    
## <a id='delete-clusters'></a> Delete Clusters

You can delete a cluster that you no longer require.  

To avoid an incomplete deletion, prepare the cluster for deletion before deleting it:  

1. If the cluster is configured with a PodDisruptionBudget (PDB), remove the PDB from the cluster.  
1. Remove all static and dynamic PVCs from the cluster.  
1. Remove all PVs with a reclaimPolicy of `Retain` from the cluster.

    <p class="note"><strong>Note</strong>: Before deleting a cluster, 
    remove the PVs and PVCs from the cluster to avoid making orphan disks of the cluster's attached disks.
    </p>
    
<br>
To delete a cluster:  

1. Go to the **TKG Integrated Edition** view of the management console.  
1. Select the **Clusters** tab.
1. Select the cluster to be deleted
1. Click **Delete**.
    ![Delete cluster](images/console/delete-cluster.png)

## <a id='next-steps'></a> Next Steps

- [Monitor and Manage Clusters, Nodes, and Namespaces in the Management Console](console-monitor-manage-clusters.html)
- [Connect to Clusters with kubectl](console-monitor-manage-clusters.html#kubectl)